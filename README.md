# mlmodels : Model ZOO for Pytorch, Tensorflow, Keras, Gluon, LightGBM, Sklearn models...

- Model ZOO with Lightweight Functional interface to wrap access to Recent and State of Art Deep Learning, ML models and Hyper-Parameter Search, cross platforms such as Tensorflow, Pytorch, Gluon, Keras, sklearn, light-GBM,...

- Logic follows sklearn : fit, predict, transform, metrics, save, load

- Goal is to transform Script/Research code into Re-usable/batch/ code with minimal code change ...

- Why Functional interface instead of pure OOP ?
  Functional reduces the amount of code needed, focus more on the computing part (vs design part),
  a bit easier maintenability for medium size project, good for scientific computing process.


*  Usage, Example :
https://github.com/arita37/mlmodels/blob/dev/mlmodels/example/README_usage.md


*  Colab demo for Install :
https://colab.research.google.com/drive/1sYbrXNZh9nTeizS-AuCA8RSu94B_B-RF


## Model List :
### Self supervised learning

UNSUPERVISED FEW-SHOT LEARNING VIA SELFSUPERVISED TRAINING.
https://arxiv.org/pdf/1912.12178.pdf  

Multiple Pretext-Task for Self-Supervised Learning via Mixing Multiple Image Transformations.
https://arxiv.org/pdf/1912.11603.pdf    

NEURAL OUTLIER REJECTION FOR SELF-SUPERVISED KEYPOINT LEARNING.
https://arxiv.org/pdf/1912.10615.pdf    

Multimodal Self-Supervised Learning for Medical Image Analysis. 
https://arxiv.org/pdf/1912.05396.pdf    

Self-Supervised 3D Keypoint Learning for Ego-motion Estimation.
https://arxiv.org/pdf/1912.03426.pdf  

Self-Supervised Visual Terrain Classification from Unsupervised Acoustic Feature Learning. 
https://arxiv.org/pdf/1912.03227.pdf    

Self-Supervised Learning of Video-Induced Visual Invariances. 
https://arxiv.org/pdf/1912.02783.pdf    

Self-Supervised Learning of Pretext-Invariant Representations. 
https://arxiv.org/pdf/1912.01991.pdf   

Self-Supervised Learning by Cross-Modal Audio-Video Clustering.
https://arxiv.org/pdf/1911.12667.pdf  

Revisiting Image Aesthetic Assessment via Self-Supervised Feature Learning. 
https://arxiv.org/pdf/1911.11419.pdf    

EnAET: Self-Trained Ensemble AutoEncoding Transformations for Semi-Supervised Learning. 
https://arxiv.org/pdf/1911.09265.pdf   

AETv2: AutoEncoding Transformations for Self-Supervised Representation Learning by Minimizing Geodesic Distances in Lie Groups.
https://arxiv.org/pdf/1911.07004.pdf    


Self-supervised Feature Learning by Cross-modality and Cross-view Correspondences. 
https://arxiv.org/pdf/2004.05749.pdf    

Temporally Coherent Embeddings for Self-Supervised Video Representation Learning.
https://arxiv.org/pdf/2004.02753.pdf    

SelfORE: Self-supervised Relational Feature Learning for Open Relation Extraction. 
https://arxiv.org/pdf/2004.02438.pdf    

Steering Self-Supervised Feature Learning Beyond Local Pixel Statistics.
https://arxiv.org/pdf/2004.02331.pdf    

Flow2Stereo: Effective Self-Supervised Learning of Optical Flow and Stereo Matching. 
https://arxiv.org/pdf/2004.02138.pdf    

Exploit Clues from Views: Self-Supervised and Regularized Learning for Multiview Object Recognition.
https://arxiv.org/pdf/2003.12735.pdf  

Self-Supervised Learning for Domain Adaptation on Point-Clouds.
https://arxiv.org/pdf/2003.12641.pdf    

ATTENTION-BASED SELF-SUPERVISED FEATURE LEARNING FOR SECURITY DATA.
https://arxiv.org/pdf/2003.10639.pdf    

Fast(er) Reconstruction of Shredded Text Documents via Self-Supervised Deep Asymmetric Metric Learning.
https://arxiv.org/pdf/2003.10063.pdf    

Cross-domain Self-supervised Learning for Domain Adaptation with Few Source Labels.
https://arxiv.org/pdf/2003.08264.pdf  

Self-Supervised Discovering of Causal Features: Towards Interpretable Reinforcement Learning.
https://arxiv.org/pdf/2003.07069.pdf    

Online Self-Supervised Learning for Object Picking: Detecting Optimum Grasping Position using a Metric Learning Approach.
https://arxiv.org/pdf/2003.03717.pdf  

Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning.
https://arxiv.org/pdf/2003.03186.pdf    

Self-Supervised Spatio-Temporal Representation Learning Using Variable Playback Speed Prediction.
https://arxiv.org/pdf/2003.02692.pdf   

Self-Supervised Graph Representation Learning via Global Context Prediction.
https://arxiv.org/pdf/2003.01604.pdf    

Self-Supervised Object-Level Deep Reinforcement Learning. 
https://arxiv.org/pdf/2003.01384.pdf 

A Self-Supervised Learning Approach to Rapid Path Planning for Car-Like Vehicles Maneuvering in Urban Environment.
https://arxiv.org/pdf/2003.00946.pdf    

A Multi-view Perspective of Self-supervised Learning.
https://arxiv.org/pdf/2003.00877.pdf   

MVP: Unified Motion and Visual Self-Supervised Learning for Large-Scale Robotic Navigation.
https://arxiv.org/pdf/2003.00667.pdf    

Self-Supervised Viewpoint Learning From Image Collections.
https://arxiv.org/pdf/2004.01793.pdf    

Deep Active Learning for Biased Datasets via Fisher Kernel Self-Supervision.
https://arxiv.org/pdf/2003.00393.pdf    

SELF-SUPERVISED REPRESENTATION LEARNING FOR ULTRASOUND VIDEO.
https://arxiv.org/pdf/2003.00105.pdf    

SEMANTICALLY-GUIDED REPRESENTATION LEARNING FOR SELF-SUPERVISED MONOCULAR DEPTH.
https://arxiv.org/pdf/2002.12319.pdf   

Learning a Directional Soft Lane Affordance Model for Road Scenes. 
https://arxiv.org/pdf/2002.11477.pdf    

Automatic Shortcut Removal for Self-Supervised Representation Learning.
https://arxiv.org/pdf/2002.08822.pdf   

BADGR: An Autonomous Self-Supervised Learning-Based Navigation System. 
https://arxiv.org/pdf/2002.05700.pdf    

SELF-SUPERVISED LEARNING FOR AUDIO-VISUAL SPEAKER DIARIZATION. 
https://arxiv.org/pdf/2002.05314.pdf    

SELF-SUPERVISED ECG REPRESENTATION LEARNING FOR EMOTION RECOGNITION.
https://arxiv.org/pdf/2002.03898.pdf 

Deep Self-Supervised Representation Learning for Free-Hand Sketch. 
https://arxiv.org/pdf/2002.00867.pdf    

MULTI-TASK SELF-SUPERVISED LEARNING FOR ROBUST SPEECH RECOGNITION.
https://arxiv.org/pdf/2001.09239.pdf    

Curriculum Labeling: Self-paced Pseudo-Labeling for Semi-Supervised Learning.
https://arxiv.org/pdf/2001.06001.pdf    

Self-supervised visual feature learning with curriculum. 
https://arxiv.org/pdf/2001.05634.pdf   

VISUALLY GUIDED SELF SUPERVISED LEARNING OF SPEECH REPRESENTATIONS. 
https://arxiv.org/pdf/2001.04316.pdf    

Self-Supervised Fast Adaptation for Denoising via Meta-Learning.
https://arxiv.org/pdf/2001.02899.pdf    

Few-shot Learning with Multi-scale Self-supervision.
https://arxiv.org/pdf/2001.01600.pdf    

Robust Self-Supervised Learning of Deterministic Errors in Single-Plane (Monoplanar) and Dual-Plane (Biplanar) X-ray Fluoroscopy.
https://arxiv.org/ftp/arxiv/papers/2001/2001.00686.pdf   

Self-Supervised Learning of Generative Spin-Glasses with Normalizing Flows.
https://arxiv.org/pdf/2001.00585.pdf    

Video Cloze Procedure for Self-Supervised Spatio-Temporal Learning.
https://arxiv.org/pdf/2001.00294.pdf   


### NLI 
Learning Credal Sum Product Networks 
 https://openreview.net/pdf?id=3-Tc21z1Ub
 https://github.com/arranger1044/awesome-spn

Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence 
https://www.aclweb.org/anthology/N19-1035.pdf
https://github.com/HSLCY/ABSA-BERT-pair

Auto-Encoding Scene Graphs for Image Captioning. 
http://openaccess.thecvf.com/content_CVPR_2019/papers/Yang_Auto-Encoding_Scene_Graphs_for_Image_Captioning_CVPR_2019_paper.pdf
https://github.com/yangxuntu/SGAE

CGMH: Constrained Sentence Generation by Metropolis-Hastings Sampling. 
https://aiide.org/ojs/index.php/AAAI/article/view/4659/4537
https://github.com/NingMiao/CGMH

Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond 
https://openreview.net/pdf?id=SJlvUzJtDS
https://github.com/facebookresearch/LASER

Natural Language Inference with External Knowledge 
https://openreview.net/pdf?id=Sy3XxCx0Z
https://github.com/lukecq1231/nli

Goten: GPU-Outsourcing Trusted Execution of Neural Network Training and Prediction 
https://openreview.net/pdf?id=S1xRnxSYwS
https://github.com/goten-team/Goten

PopSGD: Decentralized Stochastic Gradient Descent in the Population Model 
https://openreview.net/pdf?id=BkgqExrYvS
https://github.com/ICLR-PopSGD/PopSGD

ADAPTING PRETRAINED LANGUAGE MODELS FOR LONG DOCUMENT CLASSIFICATION 
https://openreview.net/pdf?id=ryxW804FPH
https://github.com/cf-anonymous/long_doc

GResNet: Graph Residual Network for Reviving Deep GNNs from Suspended Animation 
https://openreview.net/pdf?id=rygHq6EFwr
https://github.com/anonymous-sourcecode/GResNet

Improving Confident-Classifiers For Out-of-distribution Detection 
https://openreview.net/pdf?id=rJeIGkBKPS
https://github.com/iclr2020-ai/ICLR2020

Self-Supervised State-Control through Intrinsic Mutual Information Rewards 
https://openreview.net/pdf?id=HygSq3VFvH
https://github.com/misc-project/misc

On Iterative Neural Network Pruning, Reinitialization, and the Similarity of Masks 
https://openreview.net/pdf?id=B1xgQkrYwS
https://github.com/iclr-8dafb2ab/iterative-pruning-reinit

Encoder-Agnostic Adaptation for Conditional Language Generation 
https://openreview.net/pdf?id=B1xq264YvH
https://github.com/anon37234/encoder-agnostic-adaptation

Zero-Shot Out-of-Distribution Detection with Feature Correlations 
https://openreview.net/pdf?id=r1g6MCEtwr
https://github.com/zeroshot-ood/ood-detection

### NLU 

Incorporating BERT into Neural Machine Translation 
https://openreview.net/pdf?id=Hyl7ygStwB
https://github.com/bert-nmt/bert-nmt

TabFact: A Large-scale Dataset for Table-based Fact Verification 
https://openreview.net/pdf?id=rkeJRhNYDH
https://github.com/ppasupat/WikiTableQuestions/releases

Probing Emergent Semantics in Predictive Agents via Question Answering 
https://openreview.net/pdf?id=Bylh2krYPr
https://github.com/deepmind/lab

Reproduction of Baselines on Label-Distribution-Aware Margin Loss and Deferred Reweighting Schedule 
https://openreview.net/pdf?id=j5ScDyYXrN
https://github.com/kaidic/LDAM-DRW

[RE] Gate Decorator: Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks 
https://openreview.net/pdf?id=hR_leftqaM
https://github.com/youzhonghui/gate-decorator-pruning/blob/b95f86a7d921432e2a149151137addd005e8e836/run/vgg16/prune.json#L26).

Reproducibility of "Augmented Neural ODEs" 
https://openreview.net/pdf?id=O1IJIoWN6p
https://reproducibility-challenge.github.io/neurips2019/task

Sample-Efficient Deep Reinforcement Learning via Episodic Backward Update 
https://openreview.net/pdf?id=Byg5D65GTS
https://github.com/vedasunkara/EBUReproducibilityChallenge/tree/master/graph4+5

[Re] Better transfer learning with inferred successor maps 
https://openreview.net/pdf?id=B1lQvpqzpr
https://github.com/attraylor/reproducing_bsr

Reproducibility Challenge – Generative Modeling by Estimating Gradients of the Data Distribution 
https://openreview.net/pdf?id=SkxCSTqG6H
https://github.com/ermongroup/ncsn


Reproducing “Towards Interpretable ReinforcementLearning Using Attention Augmented Agents” 
https://openreview.net/pdf?id=BJgtDa9GaH
https://github.com/cjlovering/interpretable-reinforcement-learning-using-attention

Lookahead Optimizer: k steps forward, 1 step back 
https://openreview.net/pdf?id=H1lPS65z6B
https://github.com/shv07/lookahead-optimizer

### Reinforcement learning
Deep Reinforcement Learning for Organ Localization in CT 
https://openreview.net/pdf?id=0vDeD2UD0S
https://github.com/superxuang/caffe_3d_faster_rcnn/issues

Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning 
https://www.aclweb.org/anthology/N19-1358.pdf
https://github.com/rajammanabrolu/KG-DQN

EMI: Exploration with Mutual Information 
http://proceedings.mlr.press/v97/kim19a/kim19a.pdf
http://proceedings.mlr.press/v97/kim19a/kim19a-supp.pdf
https://github.com/snu-mllab/EMI

Fast Neural Architecture Search of Compact Semantic Segmentation Models via Auxiliary Cells. 
http://openaccess.thecvf.com/content_CVPR_2019/papers/Nekrasov_Fast_Neural_Architecture_Search_of_Compact_Semantic_Segmentation_Models_via_CVPR_2019_paper.pdf
https://github.com/drsleep/nas-segm-pytorch

DAC Replication Report 
https://openreview.net/pdf?id=rkgLDa5zpr
https://github.com/DAC-Prime/supreme-waffle/blob/master/dac/ppoc.py

Reproducing “Towards Interpretable ReinforcementLearning Using Attention Augmented Agents” 
https://openreview.net/pdf?id=BJgtDa9GaH
https://github.com/cjlovering/interpretable-reinforcement-learning-using-attention

DPO Reproducibility Challenge Report 
https://openreview.net/pdf?id=rkgbDp5z6H
https://github.com/gwbcho/dpo-replication

[Re] A Family of Robust Stochastic Operators for Reinforcement Learning 
https://openreview.net/pdf?id=Bkee_pcM6H
https://github.com/vmayoral/basic_reinforcement_learning

[Replication] A Meta-MDP Approach to Exploration for LifelongReinforcement Learning 
https://openreview.net/pdf?id=rkedITqfpB
https://github.com/dcabatin/Meta-MDP-Reproduction

DPO Reproducibility Challenge Report 
https://openreview.net/pdf?id=rkgbDp5z6H
https://github.com/gwbcho/dpo-replication

Reproducibility Challenge: Meta-LearningRepresentations for Continual Learning 
https://openreview.net/pdf?id=H1giraczTS
https://github.com/sergiolib/reproduce_oml

Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning 
https://openreview.net/pdf?id=rygBVTVFPB
https://github.com/qwerlanksdf/L2D

### Time Series:
Nbeats: 2019, Time Series NNetwork,  https://arxiv.org/abs/1905.10437

Amazon Deep AR: 2019, Time Series NNetwork,  https://arxiv.org/abs/1905.10437

Facebook Prophet 2017, Time Series prediction,

ARMDN Advanced Time series Prediction :  2019, Associative and Recurrent Mixture Density Networks for time series.

LSTM prediction 

PocketFlow: An Automated Framework for Compressing and Accelerating Deep Neural Networks
https://openreview.net/pdf?id=H1fWoYhdim  
https://github.com/Tencent/PocketFlow 

Deep Recurrent Gaussian Process with Variational Sparse Spectrum Approximation
https://openreview.net/pdf?id=BkgosiRcKm  
https://github.com/RomanFoell/DRGP-VSS  

Reconstructing evolutionary trajectories of mutations in cancer.
https://openreview.net/pdf?id=Hkjg7N1Pz 
https://github.com/YuliaRubanova/TrackSig 

Combination of Supervised and Reinforcement Learning For Vision-Based Autonomous Control
https://openreview.net/pdf?id=BkeC_J-R- 
https://github.com/openai/baselines 


Reproducibility Challenge: Meta-LearningRepresentations for Continual Learning
 https://openreview.net/pdf?id=H1giraczTS 
 https://github.com/sergiolib/reproduce_oml  

Reproducibility of "Augmented Neural ODEs"
https://openreview.net/pdf?id=O1IJIoWN6p 
https://github.com/EmilienDupont/augmented-neural-odes/blob/5d3fdefc5eebdb4b6bdfaf74640a5cd50d5484c1/augmented-neural-ode-example.ipynb 

Unsupervised Scalable Representation Learning for Multivariate Time Series. 
https://openreview.net/pdf?id=HyxQr65z6S 
https://github.com/hfawaz/dl-4-tsc 

Neural Tangents: Fast and Easy Infinite Neural Networks in Python.  
https://openreview.net/pdf?id=SklD9yrFPS  
https://github.com/google/neural-tangents 


Optimistic Exploration even with a Pessimistic Initialisation. 
https://openreview.net/pdf?id=r1xGP6VYwH  
https://github.com/deepmind/bsuite  

Kotlin∇: A shape-safe DSL for differentiable programming. 
https://openreview.net/pdf?id=SkluMSZ08H  
https://github.com/breandan/kotlingrad

A Wild Bootstrap for Degenerate Kernel Tests 
http://papers.nips.cc/paper/5452-a-wild-bootstrap-for-degenerate-kernel-tests.pdf 
https://github.com/kacperChwialkowski/wildBootstrap 

Physiological Signal Embeddings (PHASE) via Interpretable Stacked Models.
https://openreview.net/pdf?id=SygInj05Fm  
https://github.com/slundberg/shap 

ProbGAN: Towards Probabilistic GAN with Theoretical Guarantees.
https://openreview.net/pdf?id=H1l7bnR5Ym  
https://github.com/mseitzer/pytorch-fid 

Interpolation-Prediction Networks for Irregularly Sampled Time Series.
https://openreview.net/pdf?id=r1efr3C9Ym  
https://github.com/jfutoma/MGP-RNN 

Practical lossless compression with latent variables using bits back coding.
https://openreview.net/pdf?id=ryE98iR5tm  
https://github.com/bits-back/bits-back  


mFLICA: An R package for Inferring Leadership of Coordination From Time Series.
https://arxiv.org/pdf/2004.06092.pdf    

Extracting correlations in earthquake time series using complex network analysis.
https://arxiv.org/pdf/2004.05415.pdf    

Pivotal tests for relevant differences in the second order dynamics of functional time series.
https://arxiv.org/pdf/2004.04724.pdf    

Extreme expectile estimation for heavy-tailed time series. 
https://arxiv.org/pdf/2004.04078.pdf    
Bootstrap Prediction Bands for Functional Time Series.
https://arxiv.org/pdf/2004.03971.pdf  

Forecasting count data using time series model with exponentially decaying covariance structure. https://arxiv.org/pdf/2004.03130.pdf  

TSInsight: A local-global attribution framework for interpretability in time-series data. 
https://arxiv.org/pdf/2004.02958.pdf 

The fractal dimension of music: Melodic contours and time series of pitch.
https://arxiv.org/ftp/arxiv/papers/2004/2004.02612.pdf    

ReRe: A Lightweight Real-time Ready-to-Go Anomaly Detection Approach for Time Series.
https://arxiv.org/ftp/arxiv/papers/2004/2004.02319.pdf  

Modeling Rare Interactions in Time Series Data Through Qualitative Change: Application to Outcome Prediction in Intensive Care Units. 
https://arxiv.org/pdf/2004.01431.pdf 

From Fourier to Koopman: Spectral Methods for Long-term Time Series Prediction
https://arxiv.org/pdf/2004.00574.pdf 

A polynomial time algorithm to compute the connected tree-width of a series-parallel graph
https://arxiv.org/pdf/2004.00547.pdf  

ANOMALY DETECTION IN UNIVARIATE TIME-SERIES: A SURVEY ON THE STATE-OF-THE-ART.
https://arxiv.org/pdf/2004.00433.pdf    

Discrete orthogonal polynomials as a tool for detection of small anomalies of time series:a case study of GPS final orbits.
https://arxiv.org/pdf/2004.00414.pdf    

Adversarial Attacks on Multivariate Time Series. 
https://arxiv.org/pdf/2004.00410.pdf    

Difference Attention Based Error Correction LSTM Model for Time Series Prediction. 
https://arxiv.org/ftp/arxiv/papers/2003/2003.13616.pdf  

A correspondence between temporal correlations in time series, inverse problems, and the Spherical Model.
https://arxiv.org/pdf/2003.12818.pdf   

Correlated daily time series and forecasting in the M4 competition. 
https://arxiv.org/pdf/2003.12796.pdf 

How the world’s collective attention is being paid to a pandemic:COVID-19 related 1-gram time series for 24 languages on Twitter.
https://arxiv.org/pdf/2003.12614.pdf  

ABBA: Adaptive Brownian bridge-based symbolic aggregation of time series. Steven Elsworth
https://arxiv.org/pdf/2003.12469.pdf  

Time Series Data Cleaning: From Anomaly Detection to Anomaly Repairing (Technical Report).
https://arxiv.org/pdf/2003.12396.pdf 

WHEN RAMANUJAN MEETS TIME-FREQUENCY ANALYSIS IN COMPLICATED TIME SERIES ANALYSIS.
https://arxiv.org/pdf/2004.00076.pdf  

Stationarity of Time-Series on Graph: A Generalized Approach via Transition Invariance
https://arxiv.org/pdf/2004.00298.pdf    

Financial Time Series Representation Learning. 
https://arxiv.org/pdf/2003.12194.pdf    

Zero-shot and few-shot time series forecasting with ordinal regression recurrent neural networks.
https://arxiv.org/pdf/2003.12162.pdf   

Scalable Deployment of AI Time-series Models for IoT. 
https://arxiv.org/pdf/2003.12141.pdf 

Time series and machine learning to forecast the water quality from satellite data 
https://arxiv.org/ftp/arxiv/papers/2003/2003.11923.pdf  

On Consistency and Sparsity for High-Dimensional Functional Time Series with Application to Autoregressions.
https://arxiv.org/pdf/2003.11462.pdf  

Integrating Physiological Time Series and Clinical Notes with Deep Learning for Improved ICU Mortality Prediction.
https://arxiv.org/pdf/2003.11059.pdf  

A time series method to analyze incidence pattern and estimate reproduction number of COVID-19. 
https://arxiv.org/pdf/2003.10655.pdf  

A Multi-Quantile Regression Time Series Model with Interquantile Lipschitz Regularization for Wind Power Probabilistic Forecasting. 
https://arxiv.org/pdf/2003.09983.pdf    

Drift-Adjusted And Arbitrated Ensemble Framework For Time Series Forecasting. 
https://arxiv.org/ftp/arxiv/papers/2003/2003.09311.pdf    

IMPROVING IRREGULARLY SAMPLED TIME SERIES LEARNING WITH DENSE DESCRIPTORS OF TIME.
https://arxiv.org/pdf/2003.09291.pdf    

A comparison of Hurst exponent estimators in long-range dependent curve time series. 
https://arxiv.org/pdf/2003.08787.pdf    

On neural architectures for astronomical time-series classification. 
https://arxiv.org/pdf/2003.08618.pdf    

Modeling of Multisite Precipitation Occurrences Using Latent Gaussian-based Multivariate Binary Response Time Series.
https://arxiv.org/ftp/arxiv/papers/2003/2003.07998.pdf  

Construe: a software solution for the explanation-based interpretation of time series.
https://arxiv.org/pdf/2003.07596.pdf    

Model Monitoring and Dynamic Model Selection in Travel Time-series Forecasting.
https://arxiv.org/pdf/2003.07268.pdf   

A Persistent Homology Approach to Time Series Classification. 
https://arxiv.org/pdf/2003.06462.pdf    

Statistical Inference for High Dimensional Panel Functional Time Series.
https://arxiv.org/pdf/2003.05968.pdf    

Time Series Forecasting Using LSTM Networks:A Symbolic Approach. 
https://arxiv.org/pdf/2003.05672.pdf    

Simulation of long-term time series of solar photovoltaic power: is the ERA5-land reanalysis the next big step? 
https://arxiv.org/ftp/arxiv/papers/2003/2003.04131.pdf    

A Time Series Approach To Player Churn and Conversion in Videogames. 
https://arxiv.org/pdf/2003.10287.pdf    

FORECASTING IN MULTIVARIATE IRREGULARLY SAMPLED TIME SERIES WITH MISSING VALUES.
https://arxiv.org/pdf/2004.03398.pdf    

###VAE 

Practical lossless compression with latent variables using bits back coding 
https://openreview.net/pdf?id=ryE98iR5tm  
https://github.com/bits-back/bits-back  

Variational Inference of Disentangled Latent Concepts from Unlabeled Observations
https://openreview.net/pdf?id=H1kG7GZAW 
https://github.com/deepmind/dsprites-dataset

Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information 
https://openreview.net/pdf?id=BJeWUs05KQ  
https://github.com/deepmind/dm_control  

Practical lossless compression with latent variables using bits back coding
https://openreview.net/pdf?id=ryE98iR5tm  
https://github.com/bits-back/bits-back  

GO Gradient for Expectation-Based Objectives
https://openreview.net/pdf?id=ryf6Fs09YX  
https://github.com/yorkerlin/VB-MixEF/blob/master/poster_workshop.pdf 

Practical lossless compression with latent variables using bits back coding 
https://openreview.net/pdf?id=ryE98iR5tm 
https://github.com/bits-back/bits-back  

Switching Linear Dynamics for Variational Bayes Filtering
https://openreview.net/pdf?id=B1MbDj0ctQ  
https://github.com/emtiyaz/vmp-for-svae 

ISA-VAE: Independent Subspace Analysis with Variational Autoencoders
https://openreview.net/pdf?id=rJl_NhR9K7  
https://github.com/rtqichen/beta-tcvae  

Generative Models from the perspective of Continual Learning 
https://openreview.net/pdf?id=S1eFtj0cKQ  
https://github.com/anonymous-authors-2018/Generative_models_from_the_perspective_of_Continual_learning  

HyperGAN: Exploring the Manifold of Neural Networks
https://openreview.net/pdf?id=B1GHJ3R9tQ  
https://github.com/ICLR19HyperGAN/HyperGAN  

STCN: Stochastic Temporal Convolutional Networks
https://openreview.net/pdf?id=HkzSQhCcK7  
https://github.com/tensorflow/models/tree/master/research/fivo  

Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer 
https://openreview.net/pdf?id=S1fQSiCcYm  
https://github.com/anonymous-iclr-2019/acai-iclr-2019/blob/master/lrae.py#L61 

Variational Sparse Coding 
https://openreview.net/pdf?id=SkeJ6iR9Km  https://github.com/Alfo5123/Variational-Sparse-Coding 

Practical lossless compression with latent variables using bits back coding
https://openreview.net/pdf?id=ryE98iR5tm 
https://github.com/bits-back/bits-back 

Diagnosing and Enhancing VAE Models
https://openreview.net/pdf?id=B1e0X3C9tQ  
https://github.com/daib13/TwoStageVAE 


Explicitly disentangling image content from translation and rotation with spatial-VAE
https://openreview.net/pdf?id=Hyl66SBgIS  
https://github.com/tbepler/spatial-VAE  

Diagnosing and Enhancing VAE Models.
https://openreview.net/pdf?id=B1e0X3C9tQ  
https://github.com/daib13/TwoStageVAE%7D. 

D-VAE: A Variational Autoencoder for Directed Acyclic Graphs
https://openreview.net/pdf?id=r1lIr4BgIS  
https://github.com/muhanzhang/D-VAE 

Good Semi-supervised VAE Requires Tighter Evidence Lower Bound
https://openreview.net/pdf?id=S1ejj64YvS  
https://github.com/PaperCodeSubmission/ICML2020-697 

An Information Theoretic Perspective on Disentangled Representation Learning
https://openreview.net/pdf?id=rJlhYa4FPB  
https://github.com/website-for-iclr/our-dlib  

Good Semi-supervised VAE Requires Tighter Evidence Lower Bound
https://openreview.net/pdf?id=S1ejj64YvS  
https://github.com/PaperCodeSubmission/ICML2020-697 

Disentanglement by Nonlinear ICA with General Incompressible-flow Networks (GIN) 
https://openreview.net/pdf?id=rygeHgSFDH  
https://github.com/deepmind/dsprites-dataset  

RTC-VAE: HARNESSING THE PECULIARITY OF TOTAL CORRELATION IN LEARNING DISENTANGLED REPRESENTATIONS
https://openreview.net/pdf?id=SkeuipVKDH  
https://github.com/google-research/disentanglement_lib  

RaCT: Toward Amortized Ranking-Critical Training For Collaborative Filtering
https://openreview.net/pdf?id=HJxR7R4FvS  
https://github.com/samlobel/RaCT_CF 

Augmenting Genetic Algorithms with Deep Neural Networks for Exploring the Chemical Space
https://openreview.net/pdf?id=H1lmyRNFvr 
https://github.com/aspuru-guzik-group/GA  

Explicitly disentangling image content from translation and rotation with spatial-VAE
https://openreview.net/pdf?id=Hyl66SBgIS  
https://github.com/tbepler/spatial-VAE  


Learning to Dress 3D People in Generative Clothing 
https://arxiv.org/pdf/1907.13615  

Don't Blame the ELBO! A Linear VAE Perspective on Posterior Collapse
http://papers.nips.cc/paper/9138-dont-blame-the-elbo-a-linear-vae-perspective-on-posterior-collapse.pdf 

Generating Diverse High-Resolution Images with VQ-VAE
https://openreview.net/pdf?id=ryeBN88Ku4   

WiSE-ALE: Wide Sample Estimator for Approximate Latent Embedding.
https://arxiv.org/pdf/1902.06160.pdf 

Diagnosing and Enhancing VAE Models.
https://arxiv.org/pdf/1903.05789.pdf  

VV-Net: Voxel VAE Net With Group Convolutions for Point Cloud Segmentation.
http://openaccess.thecvf.com/content_ICCV_2019/papers/Meng_VV-Net_Voxel_VAE_Net_With_Group_Convolutions_for_Point_Cloud_ICCV_2019_paper.pdf   

Uncertainty Analysis of VAE-GANs for Compressive Medical Imaging
https://arxiv.org/pdf/1901.11228.pdf  

Disentangling Latent Space for VAE by Label Relevant/Irrelevant Dimensions.
http://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Disentangling_Latent_Space_for_VAE_by_Label_RelevantIrrelevant_Dimensions_CVPR_2019_paper.pdf 

Dr.VAE: improving drug response prediction via modeling of drug perturbation effects.
https://academic.oup.com/bioinformatics/article-pdf/35/19/3743/30061484/btz158.pdf 

PQ-VAE:Efficient Recommendation Using Quantized Embeddings
http://ceur-ws.org/Vol-2431/paper10.pdf 

Bayes-Factor-VAE: Hierarchical Bayesian Deep Auto-Encoder Models for Factor Disentanglement Minyoung
http://openaccess.thecvf.com/content_ICCV_2019/papers/Kim_Bayes-Factor-VAE_Hierarchical_Bayesian_Deep_Auto-Encoder_Models_for_Factor_Disentanglement_ICCV_2019_paper.pdf 

Improving VAE generations of multimodal data through data-dependent conditional priors.
https://arxiv.org/pdf/1911.10885 

D-VAE: A Variational Autoencoder for Directed Acyclic Graphs
http://papers.nips.cc/paper/8437-d-vae-a-variational-autoencoder-for-directed-acyclic-graphs.pdf    

Explicitly disentangling image content from translation and rotation with spatial-VAE
http://papers.nips.cc/paper/9677-explicitly-disentangling-image-content-from-translation-and-rotation-with-spatial-vae.pdf   

Solving Inverse Problems by Joint Posterior Maximization with a VAE Prior.
https://arxiv.org/pdf/1911.06379   

ODE2VAE: Deep generative second order ODEs with Bayesian neural networks.
https://arxiv.org/pdf/1905.10994  

Relevance Factor VAE: Learning and Identifying Disentangled Factors
https://arxiv.org/pdf/1902.01568.pdf  

Joint haze image synthesis and dehazing with mmd-vae losses
https://arxiv.org/pdf/1905.05947  

Semi-supervised Open Domain Information Extraction with Conditional VAE
https://sailinglab.github.io/pgm-spring-2019/assets/project/final-reports/project22.pdf   

Inf-VAE: A Variational Autoencoder Framework to Integrate Homophily and Influence in Diffusion Prediction. 
https://arxiv.org/pdf/2001.00132   

Sequential VAE-LSTM for Anomaly Detection on Time Series.
https://arxiv.org/pdf/1910.03818    

Bayesian EDDI: Sequential Variable Selection with Bayesian Partial VAE.
http://www.tschiatschek.net/files/ma2019BayesianEDDI.pdf  

Increasing Expressivity of a Hyperspherical VAE
https://arxiv.org/pdf/1910.02912    
VAE-based regularization for deep speaker embedding.
https://arxiv.org/pdf/1904.03617 

G-VAE: A Continuously Variable Rate Deep Image Compression Framework.
https://arxiv.org/pdf/2003.02012  

Multi-Angle Point Cloud-VAE: Unsupervised Feature Learning for 3D Point Clouds from Multiple Angles by Joint Self-Reconstruction and Half-to-Half Prediction 
https://arxiv.org/pdf/1907.12704    

Coupled VAE: Improved Accuracy and Robustness of a Variational Autoencoder.
https://arxiv.org/pdf/1906.00536    

The Usual Suspects? Reassessing Blame for VAE Posterior Collapse.
https://arxiv.org/pdf/1912.10702 

Disentangling the Spatial Structure and Style in Conditional VAE.
https://arxiv.org/pdf/1910.13062    

Inspecting and Interacting with Meaningful Music Representations using VAE.
https://arxiv.org/pdf/1904.08842 

An Interactive Insight Identification and Annotation Framework for Power Grid Pixel Maps using DenseU-Hierarchical VAE.
https://arxiv.org/pdf/1905.12164    

Class-Conditional VAE-GAN for Local-Ancestry Simulation.
https://arxiv.org/pdf/1911.13220   

VAE-based Domain Adaptation for Speaker Verification. 
https://arxiv.org/pdf/1908.10092   

Constructing the Matrix Multilayer Perceptron and its Application to the VAE.
https://arxiv.org/pdf/1902.01182    

Dynamic Narrowing of VAE Bottlenecks Using GECO and L0 Regularization.
https://arxiv.org/pdf/2003.10901    

MIDI-Sandwich2: RNN-based Hierarchical Multi-modal Fusion Generation VAE networks for multi-track symbolic music generation. 
https://arxiv.org/pdf/1909.03522   

Program Synthesis and Vulnerability Injection Using a Grammar VAE
https://pdfs.semanticscholar.org/e21b/233996437b0bafdb253fe18c29b5b535ce7b.pdf    

SAG-VAE: End-to-end Joint Inference of Data Representations and Feature Relations 
https://arxiv.org/pdf/1911.11984   

A Closer Look at Disentangling in β-VAE.
https://arxiv.org/pdf/1912.05127   

Mixture of Inference Networks for VAE-based Audio-visual Speech Enhancement.
https://arxiv.org/pdf/1912.10647  

CBN-VAE: A Data Compression Model with Efficient Convolutional Structure for Wireless Sensor Networks.
https://www.mdpi.com/1424-8220/19/16/3445/pdf   

Generated Loss and Augmented Training of MNIST VAE. 
https://arxiv.org/pdf/1904.10937  

Learning Facial Recognition Biases through VAE Latent Representations. 
https://dl.acm.org/doi/pdf/10.1145/3347447.3356752    

The Gaussian Process Prior VAE for Interpretable Latent Dynamics from Pixels 
http://proceedings.mlr.press/v118/pearce20a/pearce20a.pdf   

Class-Conditional VAE-GAN for Local-Ancestry Simulation.
https://arxiv.org/pdf/1911.13220.pdf  

Investigating GAN and VAE to Train DCNN
http://www.ijmlc.org/vol9/872-AM1002.pdf    

MIDI-Sandwich: Multi-model Multi-task Hierarchical Conditional VAE-GAN networks for Symbolic Single-track Music Generation.
https://arxiv.org/pdf/1907.01607    

Generated Loss, Augmented Training, and Multiscale VAE.
https://arxiv.org/pdf/1904.10446  

Based on Graph-VAE Model to Predict Student's Score.
https://arxiv.org/pdf/1903.03609 

Graph Embedding VAE: A Permutation Invariant Model of Graph Structure. 
https://arxiv.org/pdf/1910.08057  

Wyner VAE: Joint and Conditional Generation with Succinct Common Representation Learning.
https://arxiv.org/pdf/1905.10945    

VAE-PGN based Abstractive Model in Multi-stage Architecture for Text Summarization.
https://www.aclweb.org/anthology/W19-8664.pdf 

Effect of VAE Latex Powder Addition on Tensile and Shear Properties of Styrene-Acrylate Based Cement Composite Joint Compound
https://iopscience.iop.org/article/10.1088/1755-1315/242/3/032063/pdf   

BooVAE: A scalable framework for continual VAE learning under boosting approach 
https://arxiv.org/pdf/1908.11853    

ρ-VAE: Autoregressive parametrization of the VAE encoder. 
https://arxiv.org/pdf/1909.06236  

M2VAE - Derivation of a Multi-Modal Variational Autoencoder Objective from the Marginal Joint Log-Likelihood. 
https://arxiv.org/pdf/1903.07303    

Progressive VAE Training on Highly Sparse and Imbalanced Data.
https://arxiv.org/pdf/1912.08283   

retina-VAE: Variationally Decoding the Spectrum of Macular Disease.
https://arxiv.org/pdf/1907.05195    
GP-VAE: Deep Probabilistic Time Series Imputation.
https://arxiv.org/pdf/1907.04155  

Latent Space Expanded Variational Autoencoder for Sentence Generation.
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8853312    


RecVAE: a New Variational Autoencoder for Top-N Recommendations with Implicit Feedback.
https://arxiv.org/pdf/1912.11160.pdf    

Concept Saliency Maps to Visualize Relevant Features in Deep Generative Models.
https://arxiv.org/pdf/1910.13140.pdf    

MIDI-Sandwich2: RNN-based Hierarchical Multi-modal Fusion Generation VAE networks for multi-track symbolic music generation
https://arxiv.org/pdf/1909.03522.pdf 

SCALABLE MODELING OF SPATIOTEMPORAL DATA USING THE VARIATIONAL AUTOENCODER: AN APPLICATION IN GLAUCOMA
https://arxiv.org/pdf/1908.09195.pdf    

Learning Discrete and Continuous Factors of Data via Alternating Disentanglement
https://arxiv.org/pdf/1905.09432.pdf 

Variational Adversarial Active Learning
https://arxiv.org/pdf/1904.00370.pdf  

Using RGB Image as Visual Input for Mapless Robot Navigation 
https://arxiv.org/ftp/arxiv/papers/1903/1903.09927.pdf    

Diagnosing and Enhancing VAE Models.
https://arxiv.org/pdf/1903.05789.pdf    

PRACTICAL LOSSLESS COMPRESSION WITH LATENT VARIABLES USING BITS BACK CODING
https://arxiv.org/pdf/1901.04866.pdf  

Defense-VAE: A Fast and Accurate Defense against Adversarial Attacks.
https://arxiv.org/pdf/1812.06570.pdf    



GOOD SEMI-SUPERVISED VAE REQUIRES TIGHTER EVIDENCE LOWER BOUND
https://openreview.net/pdf?id=S1ejj64YvS  
https://github.com/PaperCodeSubmission/ICML2020-697 

Learning Discrete and Continuous Factors of Data via Alternating Disentanglement
http://proceedings.mlr.press/v97/jeong19d/jeong19d.pdf  
https://github.com/snu-mllab/DisentanglementICML19  
http://proceedings.mlr.press/v97/jeong19d/jeong19d-supp.pdf

D-VAE: A Variational Autoencoder for Directed Acyclic Graphs
https://openreview.net/pdf?id=r1lIr4BgIS  
https://github.com/muhanzhang/D-VAE 


q-VAE for Disentangled Representation Learning and Latent Dynamical Systems.
https://arxiv.org/pdf/2003.01852 

Out-of-Distribution Detection in Multi-Label Datasets using Latent Space of β-VAE.
https://arxiv.org/pdf/2003.08740    

Robust Ordinal VAE: Employing Noisy Pairwise Comparisons for Disentanglement. 
https://arxiv.org/pdf/1910.05898    

Deterministic Decoding for Discrete Data in Variational Autoencoders.
https://arxiv.org/pdf/2003.02174.pdf 

Dimensionality Reduction of SDSS Spectra with Variational Autoencoders.
https://arxiv.org/pdf/2002.10464.pdf    

NeurIPS 2019 Disentanglement Challenge: Improved Disentanglement through Aggregated Convolutional Feature Maps.
https://arxiv.org/pdf/2002.10003.pdf    

An Explicit Local and Global Representation Disentanglement Framework with Applications in Deep Clustering and Unsupervised Object Detection.
https://arxiv.org/pdf/2001.08957.pdf    

Re-balancing Variational Autoencoder Loss for Molecule Sequence Generation 
https://arxiv.org/pdf/1910.00698.pdf    

RACT: TOWARDS AMORTIZED RANKING-CRITICAL TRAINING FOR COLLABORATIVE FILTERING 
https://arxiv.org/pdf/1906.04281.pdf    

### GAN
Perception-Enhanced Image Super-Resolution via Relativistic Generative Adversarial Networks 
https://link.springer.com/chapter/10.1007%2F978-3-030-11021-5_7 
https://github.com/thangvubk/PESR 

DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks
http://openaccess.thecvf.com/content_cvpr_2018/papers/Kupyn_DeblurGAN_Blind_Motion_CVPR_2018_paper.pdf  
https://github.com/KupynOrest/DeblurGAN 

HP-GAN: Probabilistic 3D Human Motion Prediction via GAN
http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w29/Barsoum_HP-GAN_Probabilistic_3D_CVPR_2018_paper.pdf
 https://github.com/ebarsoum/hpgan 

Image Synthesis with a Convolutional Capsule Generative Adversarial Network 
https://openreview.net/pdf?id=rJen0zC1lE  https://github.com/CherBass/CapsPix2Pix/blob/master/CapsPix2Pix_paper.pdf 

Image Synthesis with a Convolutional Capsule Generative Adversarial Network
https://openreview.net/pdf?id=rJen0zC1lE  https://github.com/lalonderodney/SegCaps  


The Unusual Effectiveness of Averaging in GAN Training
https://openreview.net/pdf?id=SJgw_sRqFQ  
https://github.com/yasinyazici/EMA_GAN  

The relativistic discriminator: a key element missing from standard GAN 
https://openreview.net/pdf?id=S1erHoR5t7  
https://github.com/AlexiaJM/RelativisticGAN 

Generating Multiple Objects at Spatially Distinct Locations
https://openreview.net/pdf?id=H1edIiA9KQ  
https://github.com/tohinz/multiple-objects-gan  

InstaGAN: Instance-aware Image-to-Image Translation
https://openreview.net/pdf?id=ryxwJhC9YX  https://github.com/sangwoomo/instagan 

Whitening and Coloring Batch Transform for GANs 
https://openreview.net/pdf?id=S1x2Fj0qKQ 
https://github.com/igul222/improved_wgan_training/blob/master/gan_cifar_resnet.py#L79

Convergent Reinforcement Learning with Function Approximation: A Bilevel Optimization Perspective
https://openreview.net/pdf?id=ryfcCo0ctQ  
https://github.com/openai/baselines 

DEEP GRAPH TRANSLATION
https://openreview.net/pdf?id=SJz6MnC5YQ  
https://github.com/anonymous1025/Deep-Graph-Translation 


Brain MRI super-resolution using 3D generative adversarial networks.
https://arxiv.org/pdf/1812.11440.pdf    


Variational Hetero-Encoder Randomized GANs for Joint Image-Text Modeling
https://openreview.net/pdf?id=H1x5wRVtvS  
https://github.com/BoChenGroup/VHE-GAN  

Unpaired Point Cloud Completion on Real Scans using Adversarial Training 
https://openreview.net/pdf?id=HkgrZ0EYwB 
https://github.com/xuelin-chen/pcl2pcl-gan-pub 

Unsupervised Video Summarization via Attention-Driven Adversarial Learning
https://link.springer.com/chapter/10.1007%2F978-3-030-37731-1_40  
https://github.com/e-apostolidis/SUM-GAN-AAE  

Learning Implicit Fields for Generative Shape Modeling.
http://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Learning_Implicit_Fields_for_Generative_Shape_Modeling_CVPR_2019_paper.pdf
 https://github.com/czq142857/implicit-decoder 

Sphere Generative Adversarial Network Based on Geometric Moment Matching.
http://openaccess.thecvf.com/content_CVPR_2019/papers/Park_Sphere_Generative_Adversarial_Network_Based_on_Geometric_Moment_Matching_CVPR_2019_paper.pdf 
https://github.com/pswkiki/SphereGAN  

Improving GAN with Neighbors Embedding and Gradient Matching.
https://www.aaai.org/ojs/index.php/AAAI/article/view/4454/4332 
https://github.com/tntrung/gan  

FineGAN: Unsupervised Hierarchical Disentanglement for Fine-Grained Object Generation and Discovery.
http://openaccess.thecvf.com/content_CVPR_2019/papers/Singh_FineGAN_Unsupervised_Hierarchical_Disentanglement_for_Fine-Grained_Object_Generation_and_Discovery_CVPR_2019_paper.pdf 
https://github.com/kkanshul/finegan

Consistency Regularization for Generative Adversarial Networks
https://openreview.net/pdf?id=S1lxKlSKPH  
https://github.com/google/compare_gan/blob/19922d3004b675c1a49c4d7515c06f6f75acdcc8/compare_gan/architectures/sndcgan.py#L121 


Non-Sequential Melody Generation 
https://openreview.net/pdf?id=HkePOCNtPH  
https://github.com/gan-music-generation/gan_music_generation  

Imagining the Latent Space of a Variational Auto-Encoders
https://openreview.net/pdf?id=BJe4PyrFvB 
https://github.com/iclr-2020-zzz/LSR-GAN  

Attributing Fake Images to GANs: Learning and Analyzing GAN Fingerprints 
https://arxiv.org/pdf/1811.08180.pdf  
https://github.com/ningyu1991/GANFingerprints 

Beholder-Gan: Generation and Beautification of Facial Images with Conditioning on Their Beauty Level
https://openreview.net/pdf?id=B1g6V5DF2H  
https://github.com/beholdergan/Beholder-GAN 

Adaptive Generation of Unrestricted Adversarial Inputs
https://openreview.net/pdf?id=rJg46kHYwH  
https://github.com/ajbrock/BigGAN-PyTorch 

Improving Model Compatibility of Generative Adversarial Networks by Boundary Calibration
https://openreview.net/pdf?id=S1xJikHtDH  
https://github.com/MichaelArbel/Scaled-MMD-GAN  

Generalized Zero-shot ICD Coding
https://openreview.net/pdf?id=S1lBTerYwH  
https://github.com/google-research/bert/blob/master/README.md#out-of-memory-issues  

TOWARDS FEATURE SPACE ADVERSARIAL ATTACK
https://openreview.net/pdf?id=S1eqj1SKvr  
https://github.com/JerishDansolBalala/FeatureSpaceAtk 

Progressive Compressed Records: Taking a Byte Out of Deep Learning Data
https://openreview.net/pdf?id=S1e0ZlHYDB 
https://github.com/tkarras/progressive_growing_of_gans#preparing-datasets-for-training 

Score and Lyrics-Free Singing Voice Generation
https://openreview.net/pdf?id=HygcdeBFvr 
https://github.com/keums/melodyExtraction_JDC 

Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators
https://openreview.net/pdf?id=Hye1RJHKwB  
https://github.com/aalmah/augmented_cyclegan  

UWGAN: UNDERWATER GAN FOR REAL-WORLD UNDERWATER COLOR RESTORATION AND DEHAZING
https://openreview.net/pdf?id=HkgMxkHtPH  
https://github.com/infrontofme/UWGAN_UIE  

Adversarial Lipschitz Regularization
https://openreview.net/pdf?id=Bke_DertPB  
https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py 

Language GANs Falling Short
https://openreview.net/pdf?id=BJgza6VtPB  
https://github.com/pclucas14/GansFallingShort 

RPGAN: random paths as a latent space for GAN interpretability
https://openreview.net/pdf?id=BJgctpEKwr  https://github.com/rpgan-ICLR2020/RPGAN 

BRIDGING ADVERSARIAL SAMPLES AND ADVERSARIAL NETWORKS
https://openreview.net/pdf?id=rklPITVKvS  
https://github.com/mseitzer/pytorch-fid 

LIA: Latently Invertible Autoencoder with Adversarial Learning
https://openreview.net/pdf?id=ryefE1SYDr  
https://github.com/genforce/interfacegan 

LIA: Latently Invertible Autoencoder with Adversarial Learning 
https://openreview.net/pdf?id=ryefE1SYDr  
https://github.com/genforce/interfacegan  

Observational Overfitting in Reinforcement Learning
https://openreview.net/pdf?id=HJli2hNKDH  
https://github.com/openai/baselines/blob/master/baselines/ppo2/ppo2.py#L21  

Language GANs Falling Short
https://openreview.net/pdf?id=BJgza6VtPB 
https://github.com/pclucas14/GansFallingShort 

Expected Information Maximization: Using the I-Projection for Mixture Density Estimation 
https://openreview.net/pdf?id=ByglLlHFDS 
https://github.com/pbecker93/ExpectedInformationMaximization 

Expected Information Maximization: Using the I-Projection for Mixture Density Estimation 
https://openreview.net/pdf?id=ByglLlHFDS  
https://github.com/pbecker93/ExpectedInformationMaximization 

Expected Information Maximization: Using the I-Projection for Mixture Density Estimation
https://openreview.net/pdf?id=ByglLlHFDS  
https://github.com/pbecker93/ExpectedInformationMaximization  

BRIDGING ADVERSARIAL SAMPLES AND ADVERSARIAL NETWORKS
https://openreview.net/pdf?id=rklPITVKvS  
https://github.com/mseitzer/pytorch-fid 

Implicit competitive regularization in GANs
https://openreview.net/pdf?id=SkxaueHFPB  https://github.com/EmilienDupont/wgan-gp/blob/master/models.py  

Progressive Augmentation of GANs
https://openreview.net/pdf?id=B1fJj4SeUS 
https://github.com/boschresearch/PA-GAN 

Learning from Label Proportions with Generative Adversarial Networks
https://openreview.net/pdf?id=HJe-nESlIH  
https://github.com/liujiabin008/LLP-GAN 

Shape Features Improve General Model
https://openreview.net/pdf?id=SJlPZlStwS  
https://github.com/bethgelab/foolbox  

High Fidelity Speech Synthesis with Adversarial Networks
https://openreview.net/pdf?id=r1gfQgSFDr  
https://github.com/mbinkowski/DeepSpeechDistances 

Small-GAN: Speeding up GAN Training using Core-Sets
https://openreview.net/pdf?id=rkeNr6EKwB 
https://github.com/heykeetae/Self-Attention-GAN 

Defense against Adversarial Examples by Encoder-Assisted Search in the Latent Coding Space
https://openreview.net/pdf?id=Hyg53gSYPB  
https://github.com/anishathalye/obfuscated-gradients  


PAGANDA: An Adaptive Task-Independent Automatic Data Augmentation
https://openreview.net/pdf?id=S1xKEqrs3E  
https://github.com/miaojiang1987/k-folder-data-augmentation-gan/  


Asymmetric Generative Adversarial Networks for Image-to-Image Translation
https://arxiv.org/pdf/1912.06931.pdf 

cGANs with Multi-Hinge Loss
https://arxiv.org/pdf/1912.04216.pdf    

Invert and Defend: Model-based Approximate Inversion of Generative Adversarial Networks for Secure Inference
https://arxiv.org/pdf/1911.10291.pdf    

Adversarial Fisher Vectors for Unsupervised Representation Learning
https://arxiv.org/pdf/1910.13101.pdf    

Alleviating Feature Confusion for Generative Zero-shot Learning
https://arxiv.org/pdf/1909.07615.pdf   

Synthesizing Coupled 3D Face Modalities by Trunk-Branch Generative Adversarial Networks.
https://arxiv.org/pdf/1909.02215.pdf

Spectral Regularization for Combating Mode Collapse in GANs.
https://arxiv.org/pdf/1908.10999.pdf 

Adversarial regression training for visualizing the progression of chronic obstructive pulmonary disease with chest x-rays.
https://arxiv.org/pdf/1908.10468.pdf 

Learning Fixed Points in Generative Adversarial Networks: From Image-to-Image Translation to Disease Detection and Localization.
https://arxiv.org/pdf/1908.06965.pdf    

AutoGAN: Neural Architecture Search for Generative Adversarial Networks.
https://arxiv.org/pdf/1908.03835.pdf  

DeblurGAN-v2: Deblurring (Orders-of-Magnitude) Faster and Better.
https://arxiv.org/pdf/1908.03826.pdf  

Cosmological N-body simulations: a challenge for scalable generative models.
https://arxiv.org/pdf/1908.05519.pdf  

Progressive Perception-Oriented Network for Single Image Super-Resolution.
https://arxiv.org/pdf/1907.10399.pdf  

Cascade Attention Guided Residue Learning GAN for Cross-Modal Translation. 
https://arxiv.org/pdf/1907.01826.pdf    

CELLULAR STATE TRANSFORMATIONS USING GENERATIVE ADVERSARIAL NETWORKS.
https://arxiv.org/pdf/1907.00118.pdf   

Adversarial Sub-sequence for Text Generation.
https://arxiv.org/pdf/1905.12835.pdf   

Structured Coupled Generative Adversarial Networks for Unsupervised Monocular Depth Estimation. 
https://arxiv.org/pdf/1908.05794.pdf

Attention-Guided Generative Adversarial Networks for Unsupervised Image-to-Image Translation.
https://arxiv.org/pdf/1903.12296.pdf    

Diagnosing and Enhancing VAE Models.
https://arxiv.org/pdf/1903.05789.pdf   

Virtual Conditional Generative Adversarial Networks.
https://arxiv.org/pdf/1901.09822.pdf    

CSGAN: Cyclic-Synthesized Generative Adversarial Networks for Image-to-Image Transformation.
https://arxiv.org/pdf/1901.03554.pdf  

TF-REPLICATOR: DISTRIBUTED MACHINE LEARNING FOR RESEARCHERS.
https://arxiv.org/pdf/1902.00465.pdf 

4D Semantic Cardiac Magnetic Resonance Image Synthesis on XCAT Anatomical Model 
https://openreview.net/pdf?id=tRdOL-DcPA  https://github.com/NVlabs/SPADE 

Rubeus-GAN: Attacking class imbalance via conditioned generation. A medical imaging perspective   
https://openreview.net/pdf?id=UHtZuvXHoA  
https://github.com/soumith/ganhacks

Unsupervised Video Summarization via Attention-Driven Adversarial Learning  Evlampios
https://link.springer.com/chapter/10.1007%2F978-3-030-37731-1_40  
https://github.com/e-apostolidis/SUM-GAN-AAE  

Discriminative region proposal adversarial network for high-quality image-to-image translation
https://link.springer.com/content/pdf/10.1007/s11263-019-01273-2.pdf  
https://github.com/godisboy/DRPAN 

FineGAN: Unsupervised Hierarchical Disentanglement for Fine-Grained Object Generation and Discovery
http://openaccess.thecvf.com/content_CVPR_2019/papers/Singh_FineGAN_Unsupervised_Hierarchical_Disentanglement_for_Fine-Grained_Object_Generation_and_Discovery_CVPR_2019_paper.pdf  
https://github.com/kkanshul/finegan 


Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks  Emily Denton
https://papers.nips.cc/paper/5773-deep-generative-image-models-using-a-laplacian-pyramid-of-adversarial-networks.pdf  

Regression via Implicit Models and Optimal Transport Cost Minimization.
https://arxiv.org/pdf/2003.01296.pdf    

PCSGAN: Perceptual Cyclic-Synthesized Generative Adversarial Networks for Thermal and NIR to Visible Image Transformation
https://arxiv.org/pdf/2002.07082.pdf    

Image Fine-grained Inpainting
https://arxiv.org/pdf/2002.02609.pdf  

CorGAN: Correlation-Capturing Convolutional Generative Adversarial Networks for Generating Synthetic Healthcare Records
https://arxiv.org/pdf/2001.09346.pdf   

S2OMGAN: Shortcut from Remote Sensing Images to Online Maps
https://arxiv.org/pdf/2001.07712.pdf 

Freeze the Discriminator: a Simple Baseline for Fine-Tuning GANs
https://arxiv.org/pdf/2002.10964.pdf    

UWGAN: Underwater GAN for Real-world Underwater Color Restoration and Dehazing
https://arxiv.org/ftp/arxiv/papers/1912/1912.10269.pdf    

MineGAN: effective knowledge transfer from GANs to target domains with few images
https://arxiv.org/pdf/1912.05270.pdf 

AdversarialNAS: Adversarial Neural Architecture Search for GANs.
https://arxiv.org/pdf/1912.02037.pdf    

Noise Robust Generative Adversarial Networks
https://arxiv.org/pdf/1911.11776.pdf    

Self-supervised GAN: Analysis and Improvement with Multi-class Minimax Game
https://arxiv.org/pdf/1911.06997.pdf    

Reusing Discriminators for Encoding: Towards Unsupervised Image-to-Image Translation.
https://arxiv.org/pdf/2003.00273.pdf   

A NEURO-AI INTERFACE FOR EVALUATING GENERATIVE ADVERSARIAL NETWORKS.
https://arxiv.org/pdf/2003.03193.pdf   

Exploiting Deep Generative Prior for Versatile Image Restoration and Manipulation
https://arxiv.org/pdf/2003.13659.pdf   

Feature Quantization Improves GAN Training.
https://arxiv.org/pdf/2004.02088.pdf    

Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy. 
https://arxiv.org/pdf/1906.01529.pdf    

Fast Underwater Image Enhancement for Improved Visual Perception.
https://arxiv.org/pdf/1903.09766.pdf  



### NLP :
Sentence Transformers : 2019, Embedding of full sentences using BERT, https://arxiv.org/pdf/1908.10084.pdf

Transformers Classifier : Using Transformer for Text Classification, https://arxiv.org/abs/1905.05583

TextCNN Pytorch : 2016, Text CNN Classifier, https://arxiv.org/abs/1801.06287

TextCNN Keras : 2016, Text CNN Classifier, https://arxiv.org/abs/1801.06287


Baseline: Strong, Extensible, Reproducible, Deep Learning Baselines for NLP.
https://openreview.net/pdf?id=r1xEb7J15Q  
https://github.com/dpressel/baseline  


Spherical Text Embedding.
https://openreview.net/pdf?id=HylBTNBlLB 
https://github.com/yumeng5/Spherical-Text-Embedding 

Sampling Bias in Deep Active Classification: An Empirical Study.
https://arxiv.org/pdf/1909.09389.pdf  
https://github.com/drimpossible/Sampling-Bias-Active-Learning 

Named Entity Recognition in Tweets: An Experimental Study.
https://www.aclweb.org/anthology/D11-1141.pdf 
https://github.com/aritter/twitter_nlp  

Open domain event extraction from twitter.
https://dl.acm.org/doi/pdf/10.1145/2339530.2339704?download=true 
https://github.com/aritter/ 

An Open-source Framework for Multi-level Semantic Similarity Measurement.
http://aclweb.org/anthology/N/N15/N15-3016.pdf 
https://github.com/pilehvar/adw/ 


TX-Ray: Quantifying and Explaining Model-Knowledge Transfer in (Un-)Supervised NLP.
https://arxiv.org/pdf/1912.00982.pdf  

Reverse Transfer Learning: Can Word Embeddings Trained for Different NLP Tasks Improve Neural Language Models?
https://arxiv.org/pdf/1909.04130.pdf   

Do NLP Models Know Numbers? Probing Numeracy in Embeddings. 
https://arxiv.org/pdf/1909.07940.pdf    

AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models.
https://arxiv.org/pdf/1909.09251.pdf  

ATTENTION INTERPRETABILITY ACROSS NLP TASKS.
https://arxiv.org/pdf/1909.11218.pdf    

Efficiency through Auto-Sizing: Notre Dame NLP’s Submission to the WNGT 2019 Efficiency Task.
https://arxiv.org/pdf/1910.07134.pdf  

NLPExplorer: Exploring the Universe of NLP Papers.
https://arxiv.org/pdf/1910.07351.pdf 

HUBERT UNTANGLES BERT TO IMPROVE TRANSFER ACROSS NLP TASKS.
https://arxiv.org/pdf/1910.12647.pdf    

The State of NLP Literature: A Diachronic Analysis of the ACL Anthology.
https://arxiv.org/pdf/1911.03562.pdf

Drug Repurposing for Cancer: An NLP Approach to Identify Low-Cost Therapies.
https://arxiv.org/pdf/1911.07819.pdf  

ERASER: A Benchmark to Evaluate Rationalized NLP Models.
https://arxiv.org/pdf/1911.03429.pdf  

UBC-NLP at SemEval-2019 Task 6: Ensemble Learning of Offensive Content With Enhanced Training Data. 
https://arxiv.org/pdf/1906.03692.pdf    

Principled Frameworks for Evaluating Ethics in NLP Systems. 
https://arxiv.org/pdf/1906.06425.pdf    

When Low Resource NLP Meets Unsupervised Language Model: Meta-pretraining Then Meta-learning for Few-shot Text Classification.
https://arxiv.org/pdf/1908.08788.pdf   

Universal Adversarial Triggers for Attacking and Analyzing NLP.
https://arxiv.org/pdf/1908.07125.pdf    

What’s Wrong with Hebrew NLP? And How to Make it Right.
https://arxiv.org/pdf/1908.05453.pdf    

Normalyzing Numeronyms - A NLP approach. 
https://arxiv.org/pdf/1907.13356.pdf    
CFO: A Framework for Building Production NLP Systems. 
https://arxiv.org/pdf/1908.06121.pdf 

Energy and Policy Considerations for Deep Learning in NLP.
https://arxiv.org/pdf/1906.02243.pdf    

A Just and Comprehensive Strategy for Using NLP to Address Online Abuse.
https://arxiv.org/pdf/1906.01738.pdf   

System Demo for Transfer Learning across Vision and Text using Domain Specific CNN Accelerator for On-Device NLP Applications.
https://arxiv.org/pdf/1906.01145.pdf  

Towards Scalable and Reliable Capsule Networks for Challenging NLP Applications.
https://arxiv.org/pdf/1906.02829.pdf 

Automatic Generation of System Test Cases from Use Case Specifications: an NLP-based Approach.
https://arxiv.org/pdf/1907.08490.pdf 

You Shall Know a User by the Company It Keeps: Dynamic Representations for Social Media Users in NLP. 
https://arxiv.org/pdf/1909.00412.pdf    


On Evaluation of Adversarial Perturbations for Sequence-to-Sequence Models.
https://www.aclweb.org/anthology/N19-1314.pdf 
https://github.com/pmichel31415/teapot-nlp  

FLAIR: An Easy-to-Use Framework for State-of-the-Art NLP. 
https://www.aclweb.org/anthology/N19-4010.pdf 
https://github.com/flairNLP/flair 

Approximating Word Ranking and Negative Sampling for Word Embedding.
https://www.ijcai.org/proceedings/2018/0569.pdf 
https://github.com/ouououououou/OptRank 

Improving Neural Fine-Grained Entity Typing With Knowledge Attention.
https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16321/16167 
https://github.com/thunlp/KNET  

Language Models as Knowledge Bases? 
https://www.aclweb.org/anthology/D19-1250.pdf 
https://github.com/facebookresearch/LAMA  


Towards Faithfully Interpretable NLP Systems:How should we define and evaluate faithfulness?
https://arxiv.org/pdf/2004.03685.pdf    

Operationalizing the legal concept of ‘Incitement to Hatred’ as an NLP task.
https://arxiv.org/pdf/2004.03422.pdf 

Orchestrating NLP Services for the Legal Domain.
https://arxiv.org/pdf/2003.12900.pdf    

Word2Vec: Optimal Hyper-Parameters and Their Impact on NLP Downstream Tasks.
https://arxiv.org/pdf/2003.11645.pdf

Parsing Thai Social Data: A New Challenge for Thai NLP.
https://arxiv.org/ftp/arxiv/papers/2003/2003.03069.pdf  

HyperEmbed: Tradeoffs Between Resources and Performance in NLP Tasks with Hyperdimensional Computing enabled Embedding of n-gram Statistics.
https://arxiv.org/pdf/2003.01821.pdf

A Nepali Rule Based Stemmer and its performance on different NLP applications
https://arxiv.org/ftp/arxiv/papers/2002/2002.09901.pdf  

Performance Comparison of Crowdworkers and NLP Tools on Named-Entity Recognition and Sentiment Analysis of Political Tweets
https://arxiv.org/pdf/2002.04181.pdf  

autoNLP: NLP Feature Recommendations for Text Analytics Applications
https://arxiv.org/pdf/2002.03056.pdf   

FASTWORDBUG: A FAST METHOD TO GENERATE ADVERSARIAL TEXT AGAINST NLP APPLICATIONS.
https://arxiv.org/pdf/2002.00760.pdf    

SemClinBr – a multi-institutional and multi-specialty semantically annotated corpus for Portuguese clinical NLP tasks.
https://arxiv.org/ftp/arxiv/papers/2001/2001.10071.pdf    

Applying Recent Innovations from NLP to MOOC Student Course Trajectory Modeling. 
https://arxiv.org/pdf/2001.08333.pdf    

Elephant in the Room: An Evaluation Framework for Assessing Adversarial Examples in NLP. 
https://arxiv.org/pdf/2001.07820.pdf   

Dice Loss for Data-imbalanced NLP Tasks.  
https://arxiv.org/pdf/1911.02855.pdf    

R2DE: a NLP approach to estimating IRT parameters of newly generated questions. 
https://arxiv.org/pdf/2001.07569.pdf    

Evaluating NLP Models via Contrast Sets.
https://arxiv.org/pdf/2004.02709.pdf  

PLAYING THE LOTTERY WITH REWARDS AND MULTIPLE LANGUAGES: LOTTERY TICKETS IN RL AND NLP.
https://arxiv.org/pdf/1906.02768.pdf  


charCNN Keras : Text Character Classifier,https://ieeexplore.ieee.org/abstract/document/8852406


DRMM:  Deep Relevance Matching Model for Ad-hoc Retrieval.https://dl.acm.org/doi/pdf/10.1145/2983323.2983769?download=true

DRMMTKS:  Deep Top-K Relevance Matching Model for Ad-hoc Retrieval. 
https://link.springer.com/chapter/10.1007/978-3-030-01012-6_2

ARC-I:  Convolutional Neural Network Architectures for Matching Natural Language Sentences
http://papers.nips.cc/paper/5550-convolutional-neural-network-architectures-for-matching-natural-language-sentences.pdf

ARC-II:  Convolutional Neural Network Architectures for Matching Natural Language Sentences
http://papers.nips.cc/paper/5550-convolutional-neural-network-architectures-for-matching-natural-language-sentences.pdf

DSSM:  Learning Deep Structured Semantic Models for Web Search using Clickthrough Data
https://dl.acm.org/doi/pdf/10.1145/2505515.2505665

CDSSM:  Learning Semantic Representations Using Convolutional Neural Networks for Web Search
https://dl.acm.org/doi/pdf/10.1145/2567948.2577348

MatchLSTM: Machine Comprehension Using Match-LSTM and Answer Pointer
https://arxiv.org/pdf/1608.07905

DUET:  Learning to Match Using Local and Distributed Representations of Text for Web Search
https://dl.acm.org/doi/pdf/10.1145/3038912.3052579

KNRM:  End-to-End Neural Ad-hoc Ranking with Kernel Pooling
https://dl.acm.org/doi/pdf/10.1145/3077136.3080809

ConvKNRM:  Convolutional neural networks for soft-matching n-grams in ad-hoc search
https://dl.acm.org/doi/pdf/10.1145/3159652.3159659

ESIM:  Enhanced LSTM for Natural Language Inference
https://arxiv.org/pdf/1609.06038

BiMPM:  Bilateral Multi-Perspective Matching for Natural Language Sentences
https://arxiv.org/pdf/1702.03814

MatchPyramid:  Text Matching as Image Recognition
https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11895/12024

Match-SRNN:  Match-SRNN: Modeling the Recursive Matching Structure with Spatial RNN
https://arxiv.org/pdf/1604.04378

aNMM:  aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching Model
https://dl.acm.org/doi/pdf/10.1145/2983323.2983818

MV-LSTM:  https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11897/12030

DIIN:  Natural Lanuguage Inference Over Interaction Space
https://arxiv.org/pdf/1709.04348

HBMP:  Sentence Embeddings in NLI with Iterative Refinement Encoders
https://www.cambridge.org/core/journals/natural-language-engineering/article/sentence-embeddings-in-nli-with-iterative-refinement-encoders/AC811644D52446E414333B20FEACE00F

### TABULAR :
Neural Tangents: Fast and Easy Infinite Neural Networks in Python 
https://openreview.net/pdf?id=SklD9yrFPS
https://github.com/google/neural-tangents

Optimistic Exploration even with a Pessimistic Initialisation 
https://openreview.net/pdf?id=r1xGP6VYwH
https://github.com/deepmind/bsuite

Exploration in Reinforcement Learning with Deep Covering Options 
https://openreview.net/pdf?id=SkeIyaVtwB
https://github.com/haarnoja/sac/blob/master/sac/algos/diayn.py

Optimistic Exploration even with a Pessimistic Initialisation 
https://openreview.net/pdf?id=r1xGP6VYwH
https://github.com/deepmind/bsuite

Efficient Inference and Exploration for Reinforcement Learning 
https://openreview.net/pdf?id=rygw7aNYDS
https://github.com/deepmind/bsuite

TabNet: Attentive Interpretable Tabular Learning 
https://openreview.net/pdf?id=BylRkAEKDH
https://github.com/catboost/benchmarks/tree/master/quality_benchmarks

Regularization Learning Networks: Deep Learning for Tabular Datasets 
http://papers.nips.cc/paper/7412-regularization-learning-networks-deep-learning-for-tabular-datasets.pdf
https://github.com/irashavitt/regularization_learning_networks

TabNN: A Universal Neural Network Solution for Tabular Data 
https://openreview.net/pdf?id=r1eJssCqY7
https://github.com/Microsoft/LightGBM/tree/master/examples

DORA The Explorer: Directed Outreaching Reinforcement Action-Selection 
https://openreview.net/pdf?id=ry1arUgCW
https://github.com/nathanwang000/deep_exploration_with_E_network 

Mask Scoring R-CNN. 
http://openaccess.thecvf.com/content_CVPR_2019/papers/Huang_Mask_Scoring_R-CNN_CVPR_2019_paper.pdf
https://github.com/zjhuang22/maskscoring_rcnn

Temporal Anomaly Detection: Calibrating the Surprise. 
https://www.aaai.org/ojs/index.php/AAAI/article/view/4261/4139
https://github.com/eyalgut/TLR

Automatic Fusion of Segmentation and Tracking Labels 
https://link.springer.com/chapter/10.1007%2F978-3-030-11024-6_34
https://github.com/xulman/CTC-FijiPlugins

Viewport Proposal CNN for 360deg Video Quality Assessment. 
http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Viewport_Proposal_CNN_for_360deg_Video_Quality_Assessment_CVPR_2019_paper.pdf
https://github.com/Archer-Tatsu/V-CNN

#### LightGBM

#### AutoML Gluon  :  2020, AutoML in Gluon, MxNet using LightGBM, CatBoost


#### Auto-Keras  :  2020, Automatic Keras model selection


#### All sklearn models :

linear_model.ElasticNet\
linear_model.ElasticNetCV\
linear_model.Lars\
linear_model.LarsCV\
linear_model.Lasso\
linear_model.LassoCV\
linear_model.LassoLars\
linear_model.LassoLarsCV\
linear_model.LassoLarsIC\
linear_model.OrthogonalMatchingPursuit\
linear_model.OrthogonalMatchingPursuitCV\


svm.LinearSVC\
svm.LinearSVR\
svm.NuSVC\
svm.NuSVR\
svm.OneClassSVM\
svm.SVC\
svm.SVR\
svm.l1_min_c\


neighbors.KNeighborsClassifier\
neighbors.KNeighborsRegressor\
neighbors.KNeighborsTransformer\





#### Binary Neural Prediction from tabular data:

A Convolutional Click Prediction Model](http://ir.ia.ac.cn/bitstream/173211/12337/1/A%20Convolutional%20Click%20Prediction%20Model.pdf)             |

Deep Learning over Multi-field Categorical Data: A Case Study on User Response Prediction](https://arxiv.org/pdf/1601.02376.pdf)                    |

Product-based neural networks for user response prediction](https://arxiv.org/pdf/1611.00144.pdf)                                                   |

Wide & Deep Learning for Recommender Systems](https://arxiv.org/pdf/1606.07792.pdf)                                                                 |

DeepFM: A Factorization-Machine based Neural Network for CTR Prediction](http://www.ijcai.org/proceedings/2017/0239.pdf)                           |

Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction](https://arxiv.org/abs/1704.05194)                                 |

Deep & Cross Network for Ad Click Predictions](https://arxiv.org/abs/1708.05123)                                                                   |

Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks](http://www.ijcai.org/proceedings/2017/435) |

Neural Factorization Machines for Sparse Predictive Analytics](https://arxiv.org/pdf/1708.05027.pdf)                                               |

xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems](https://arxiv.org/pdf/1803.05170.pdf)                         |

AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks](https://arxiv.org/abs/1810.11921)                              |

Deep Interest Network for Click-Through Rate Prediction](https://arxiv.org/pdf/1706.06978.pdf)                                                       |

Deep Interest Evolution Network for Click-Through Rate Prediction](https://arxiv.org/pdf/1809.03672.pdf)                                            |

Operation-aware Neural Networks for User Response Prediction](https://arxiv.org/pdf/1904.12579.pdf)                                                |

Feature Generation by Convolutional Neural Network for Click-Through Rate Prediction ](https://arxiv.org/pdf/1904.04447)                             |

Deep Session Interest Network for Click-Through Rate Prediction ](https://arxiv.org/abs/1905.06482)                                                |

FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction](https://arxiv.org/pdf/1905.09433.pdf)   |




### VISION :
Towards Stabilizing Batch Statistics in Backward Propagation of Batch Normalization 
https://openreview.net/pdf?id=SkgGjRVKDS
https://github.com/megvii-model/MABN

Fast Neural Network Adaptation via Parameter Remapping and Architecture Search 
https://openreview.net/pdf?id=rklTmyBKPH
https://github.com/JaminFong/FNA

Certified Defenses for Adversarial Patches 
https://openreview.net/pdf?id=HyeaSkrYPH
https://github.com/Ping-C/certifiedpatchdefense

Adaptively Connected Neural Networks. 
 http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Adaptively_Connected_Neural_Networks_CVPR_2019_paper.pdf
https://github.com/wanggrun/Adaptively-Connected-Neural-Networks

Tracking by Animation: Unsupervised Learning of Multi-Object Attentive Trackers. 
http://openaccess.thecvf.com/content_CVPR_2019/papers/He_Tracking_by_Animation_Unsupervised_Learning_of_Multi-Object_Attentive_Trackers_CVPR_2019_paper.pdf
https://github.com/zhen-he/tracking-by-animation

EDVR: Video Restoration With Enhanced Deformable Convolutional Networks. 
http://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Wang_EDVR_Video_Restoration_With_Enhanced_Deformable_Convolutional_Networks_CVPRW_2019_paper.pdf
https://github.com/xinntao/EDVR

LiveBot: Generating Live Video Comments Based on Visual and Textual Contexts. 
https://aaai.org/ojs/index.php/AAAI/article/view/4656/4534
https://github.com/lancopku/livebot

A Hybrid Method for Tracking of Objects by UAVs. 
http://openaccess.thecvf.com/content_CVPRW_2019/papers/UAVision/Saribas_A_Hybrid_Method_for_Tracking_of_Objects_by_UAVs_CVPRW_2019_paper.pdf
https://github.com/bdrhn9/hybrid-tracker

DeepCO3: Deep Instance Co-Segmentation by Co-Peak Search and Co-Saliency Detection. 
http://openaccess.thecvf.com/content_CVPR_2019/papers/Hsu_DeepCO3_Deep_Instance_Co-Segmentation_by_Co-Peak_Search_and_Co-Saliency_Detection_CVPR_2019_paper.pdf
https://github.com/KuangJuiHsu/DeepCO3/

Art2Real: Unfolding the Reality of Artworks via Semantically-Aware Image-To-Image Translation. 
http://openaccess.thecvf.com/content_CVPR_2019/papers/Tomei_Art2Real_Unfolding_the_Reality_of_Artworks_via_Semantically-Aware_Image-To-Image_Translation_CVPR_2019_paper.pdf
https://github.com/aimagelab/art2real

ELASTIC: Improving CNNs With Dynamic Scaling Policies. 
http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_ELASTIC_Improving_CNNs_With_Dynamic_Scaling_Policies_CVPR_2019_paper.pdf
https://github.com/allenai/elastic

Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification. 
https://www.aaai.org/ojs/index.php/AAAI/article/view/4604/4482
https://github.com/thunlp/

Recursive Visual Attention in Visual Dialog. 
http://openaccess.thecvf.com/content_CVPR_2019/papers/Niu_Recursive_Visual_Attention_in_Visual_Dialog_CVPR_2019_paper.pdf
https://github.com/yuleiniu/rva

Synthesis of High-Quality Visible Faces from Polarimetric Thermal Faces using Generative Adversarial Networks. 
https://link.springer.com/content/pdf/10.1007/s11263-019-01175-3.pdf
https://github.com/hezhangsprinter

MnasNet: Platform-Aware Neural Architecture Search for Mobile. 
http://openaccess.thecvf.com/content_CVPR_2019/papers/Tan_MnasNet_Platform-Aware_Neural_Architecture_Search_for_Mobile_CVPR_2019_paper.pdf
https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet

Auto-Encoding Scene Graphs for Image Captioning. 
http://openaccess.thecvf.com/content_CVPR_2019/papers/Yang_Auto-Encoding_Scene_Graphs_for_Image_Captioning_CVPR_2019_paper.pdf
https://github.com/yangxuntu/SGAE

Visualizing the Decision-making Process in Deep Neural Decision Forest. 
http://openaccess.thecvf.com/content_CVPRW_2019/papers/Explainable%20AI/Li_Visualizing_the_Decision-making_Process_in_Deep_Neural_Decision_Forest_CVPRW_2019_paper.pdf
https://github.com/Nicholasli1995/

Holistic CNN Compression via Low-Rank Decomposition with Knowledge Transfer. 
https://ieeexplore.ieee.org/document/8478366
https://github.com/ShaohuiLin/LRDKT

PointNetLK: Robust & Efficient Point Cloud Registration Using PointNet. 
http://openaccess.thecvf.com/content_CVPR_2019/papers/Aoki_PointNetLK_Robust__Efficient_Point_Cloud_Registration_Using_PointNet_CVPR_2019_paper.pdf
https://github.com/hmgoforth/PointNetLK

Learning to Parse Wireframes in Images of Man-Made Environments 
http://openaccess.thecvf.com/content_cvpr_2018/papers/Huang_Learning_to_Parse_CVPR_2018_paper.pdf
https://github.com/huangkuns/wireframe

Deep Model Transferability from Attribution Maps 
http://papers.nips.cc/paper/8849-deep-model-transferability-from-attribution-maps.pdf
https://github.com/zju-vipa/

RE] Gate Decorator: Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks 
https://openreview.net/pdf?id=hR_leftqaM
https://github.com/youzhonghui/gate-decorator-pruning/blob/b95f86a7d921432e2a149151137addd005e8e836/run/vgg16/prune.json#L26).

Direction Concentration Learning: Enhancing Congruency in Machine Learning  
https://openreview.net/pdf?id=Bp2Q4BpwdN
https://github.com/luoyan407/congruency

Deformable Convolutional Networks 
https://ieeexplore.ieee.org/document/8237351
https://github.com/msracver/Deformable-ConvNets

Improving Visual Relation Detection using Depth Maps 
https://openreview.net/pdf?id=HkxcUxrFPS
https://github.com/Sina-Baharlou/Depth-VRD

  Vision Models (pre-trained) :  
alexnet: SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size
https://arxiv.org/pdf/1602.07360
densenet121: Adversarial Perturbations Prevail in the Y-Channel of the YCbCr Color Space
https://arxiv.org/pdf/2003.00883.pdf
densenet169: Classification of TrashNet Dataset Based on Deep Learning Models
https://ieeexplore.ieee.org/abstract/document/8622212
densenet201: Utilization of DenseNet201 for diagnosis of breast abnormality
https://link.springer.com/article/10.1007/s00138-019-01042-8
densenet161: Automated classification of histopathology images using transfer learning
https://doi.org/10.1016/j.artmed.2019.101743
inception_v3: Menfish Classification Based on Inception_V3 Convolutional Neural Network
https://iopscience.iop.org/article/10.1088/1757-899X/677/5/052099/pdf 
resnet18: Leveraging the VTA-TVM Hardware-Software Stack for FPGA Acceleration of 8-bit ResNet-18 Inference
https://dl.acm.org/doi/pdf/10.1145/3229762.3229766
resnet34: Automated Pavement Crack Segmentation Using Fully Convolutional U-Net with a Pretrained ResNet-34 Encoder
https://arxiv.org/pdf/2001.01912
resnet50: Extremely Large Minibatch SGD: Training ResNet-50 on ImageNet in 15 Minutes
https://arxiv.org/pdf/1711.04325
resnet101: Classification of Cervical MR Images using ResNet101
https://www.ijresm.com/Vol.2_2019/Vol2_Iss6_June19/IJRESM_V2_I6_69.pdf
resnet152: Deep neural networks show an equivalent and often superior performance to dermatologists in onychomycosis diagnosis: Automatic construction of onychomycosis datasets by region-based convolutional deep neural network
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5774804/pdf/pone.0191493.pdf


resnext50_32x4d: Automatic Grading of Individual Knee Osteoarthritis Features in Plain Radiographs using Deep Convolutional Neural Networks
https://arxiv.org/pdf/1907.08020
resnext101_32x8d: DEEP LEARNING BASED PLANT PART DETECTION IN GREENHOUSE SETTINGS
https://efita-org.eu/wp-content/uploads/2020/02/7.-efita25.pdf

wide_resnet50_2: Identiﬁcac¸˜ao de Esp´ecies de ´Arvores por Imagens de Tronco Utilizando Aprendizado de Ma´quina Profundo
http://www.ic.unicamp.br/~reltech/PFG/2019/PFG-19-50.pdf
wide_resnet101_2: Identification of Tree Species by Trunk Images Using Deep Machine Learning
http://www.ic.unicamp.br/~reltech/PFG/2019/PFG-19-50.pdf
squeezenet1_0: Classification of Ice Crystal Habits Observed From Airborne Cloud Particle Imager by Deep Transfer Learning
https://agupubs.onlinelibrary.wiley.com/doi/epdf/10.1029/2019EA000636

squeezenet1_1: Benchmarking parts based face processing in-the-wild for gender recognition and head pose estimation
https://doi.org/10.1016/j.patrec.2018.09.023
vgg11: ernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image Segmentation
https://arxiv.org/pdf/1801.05746
vgg13: Convolutional Neural Network for Raindrop Detection
https://ieeexplore.ieee.org/abstract/document/8768613

vgg16: Automatic detection of lumen and media in the IVUS images using U-Net with VGG16 Encoder
https://arxiv.org/pdf/1806.07554
vgg19: A New Transfer Learning Based on VGG-19 Network for Fault Diagnosis
https://ieeexplore.ieee.org/abstract/document/8791884

vgg11_bn:Shifted Spatial-Spectral Convolution for Deep Neural Networks
https://dl.acm.org/doi/pdf/10.1145/3338533.3366575

vgg13_bn: DETOX: A Redundancy-based Framework for Faster and More Robust Gradient Aggregation
http://papers.nips.cc/paper/9220-detox-a-redundancy-based-framework-for-faster-and-more-robust-gradient-aggregation.pdf
vgg16_bn: Partial Convolution based Padding
https://arxiv.org/pdf/1811.11718
vgg19_bn: NeurIPS 2019 Disentanglement Challenge: Improved Disentanglement through Learned Aggregation of Convolutional Feature Maps
https://arxiv.org/pdf/2002.12356

googlenet: On the Performance of GoogLeNet and AlexNet Applied to Sketches
https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12278/11712
shufflenet_v2_x0_5: Exemplar Normalization for Learning Deep Representation
https://arxiv.org/pdf/2003.08761
shufflenet_v2_x1_0: Tree Species Identification by Trunk Images Using Deep Machine Learning
http://www.ic.unicamp.br/~reltech/PFG/2019/PFG-19-50.pdf
mobilenet_v2: MobileNetV2: Inverted Residuals and Linear Bottlenecks
http://openaccess.thecvf.com/content_cvpr_2018/papers/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.pdf

A lot more...



......

https://github.com/arita37/mlmodels/blob/dev/README_model_list.md

######################################################################################

## ① Installation

Using pre-installed online Setup :

https://github.com/arita37/mlmodels/issues/101



Manual Install as editable package in Linux

```
conda create -n py36 python=3.6.5 -y
source activate py36

cd yourfolder
git clone https://github.com/arita37/mlmodels.git mlmodels
cd mlmodels
git checkout dev
```

### Check this Colab for install :
https://colab.research.google.com/drive/1sYbrXNZh9nTeizS-AuCA8RSu94B_B-RF


##### Initialize
Will copy template, dataset, example to your folder

    ml_models --init  /yourworkingFolder/


##### To test :
    ml_optim


##### To test model fitting
    ml_models
    
        
#### Actual test runs

https://github.com/arita37/mlmodels/actions

![test_fast_linux](https://github.com/arita37/mlmodels/workflows/test_fast_linux/badge.svg)

![test_fast_windows](https://github.com/arita37/mlmodels/workflows/test_fast_windows/badge.svg?branch=dev)

![ All model testing (Linux) ](https://github.com/arita37/mlmodels/workflows/code_structure_linux/badge.svg)

#######################################################################################

## Usage in Jupyter

https://github.com/arita37/mlmodels/blob/dev/README_usage.md

#######################################################################################

## CLI tools:

https://github.com/arita37/mlmodels/blob/dev/README_usage_CLI.md



####################################################################################

## Model List

https://github.com/arita37/mlmodels/blob/dev/README_model_list.md

#######################################################################################

## How to add a new model

https://github.com/arita37/mlmodels/blob/dev/README_addmodel.md

#######################################################################################

## Index of functions/methods

https://github.com/arita37/mlmodels/blob/dev/README_index_doc.txt

####################################################################################
















### LSTM example in TensorFlow ([Example notebook](mlmodels/example/1_lstm.ipynb))

#### Define model and data definitions
```python
# import library
import mlmodels


model_uri    = "model_tf.1_lstm.py"
model_pars   =  {  "num_layers": 1,
                  "size": ncol_input, "size_layer": 128, "output_size": ncol_output, "timestep": 4,
                }
data_pars    =  {"data_path": "/folder/myfile.csv"  , "data_type": "pandas" }
compute_pars =  { "learning_rate": 0.001, }

out_pars     =  { "path": "ztest_1lstm/", "model_path" : "ztest_1lstm/model/"}
save_pars = { "path" : "ztest_1lstm/model/" }
load_pars = { "path" : "ztest_1lstm/model/" }



#### Load Parameters and Train
from mlmodels.models import module_load

module        =  module_load( model_uri= model_uri )                           # Load file definition
model         =  module.Model(model_pars=model_pars, data_pars=data_pars, compute_pars=compute_pars)             # Create Model instance
model, sess   =  module.fit(model, data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)


#### Inference
metrics_val   =  module.fit_metrics( model, sess, data_pars, compute_pars, out_pars) # get stats
ypred         = module.predict(model, sess,  data_pars, compute_pars, out_pars)     # predict pipeline


```


---

### AutoML example in Gluon ([Example notebook](mlmodels/example/gluon_automl.ipynb))
```
# import library
import mlmodels
import autogluon as ag

#### Define model and data definitions
model_uri = "model_gluon.gluon_automl.py"
data_pars = {"train": True, "uri_type": "amazon_aws", "dt_name": "Inc"}

model_pars = {"model_type": "tabular",
              "learning_rate": ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),
              "activation": ag.space.Categorical(*tuple(["relu", "softrelu", "tanh"])),
              "layers": ag.space.Categorical(
                          *tuple([[100], [1000], [200, 100], [300, 200, 100]])),
              'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),
              'num_boost_round': 10,
              'num_leaves': ag.space.Int(lower=26, upper=30, default=36)
             }

compute_pars = {
    "hp_tune": True,
    "num_epochs": 10,
    "time_limits": 120,
    "num_trials": 5,
    "search_strategy": "skopt"
}

out_pars = {
    "out_path": "dataset/"
}



#### Load Parameters and Train
from mlmodels.models import module_load

module        =  module_load( model_uri= model_uri )                           # Load file definition
model         =  module.Model(model_pars=model_pars, compute_pars=compute_pars)             # Create Model instance
model, sess   =  module.fit(model, data_pars=data_pars, model_pars=model_pars, compute_pars=compute_pars, out_pars=out_pars)      


#### Inference
ypred       = module.predict(model, data_pars, compute_pars, out_pars)     # predict pipeline


```

---

### RandomForest example in Scikit-learn ([Example notebook](mlmodels/example/sklearn.ipynb))
```
# import library
import mlmodels

#### Define model and data definitions
model_uri    = "model_sklearn.sklearn.py"

model_pars   = {"model_name":  "RandomForestClassifier", "max_depth" : 4 , "random_state":0}

data_pars    = {'mode': 'test', 'path': "../mlmodels/dataset", 'data_type' : 'pandas' }

compute_pars = {'return_pred_not': False}

out_pars    = {'path' : "../ztest"}


#### Load Parameters and Train
from mlmodels.models import module_load

module        =  module_load( model_uri= model_uri )                           # Load file definition
model         =  module.Model(model_pars=model_pars, data_pars=data_pars, compute_pars=compute_pars)             # Create Model instance
model, sess   =  module.fit(model, data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)          # fit the model


#### Inference
ypred       = module.predict(model,  data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)     # predict pipeline
```


---

### TextCNN example in keras ([Example notebook](example/textcnn.ipynb))

```python
# import library
import mlmodels

#### Define model and data definitions
model_uri    = "model_keras.textcnn.py"

data_pars    = {"path" : "../mlmodels/dataset/text/imdb.csv", "train": 1, "maxlen":400, "max_features": 10}

model_pars   = {"maxlen":400, "max_features": 10, "embedding_dims":50}
                       
compute_pars = {"engine": "adam", "loss": "binary_crossentropy", "metrics": ["accuracy"] ,
                        "batch_size": 32, "epochs":1, 'return_pred_not':False}

out_pars     = {"path": "ztest/model_keras/textcnn/"}



#### Load Parameters and Train
from mlmodels.models import module_load

module        =  module_load( model_uri= model_uri )                           # Load file definition
model         =  module.Model(model_pars=model_pars, data_pars=data_pars, compute_pars=compute_pars)             # Create Model instance
module.fit(model, data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)          # fit the model


#### Inference
data_pars['train'] = 0
ypred       = module.predict(model,  data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)
```

---

### Using json config file for input ([Example notebook](example/1_lstm_json.ipynb), [JSON file](mlmodels/mlmodels/example/1_lstm.json))

#### Import library and functions
```python
# import library
import mlmodels

#### Load model and data definitions from json
from mlmodels.models import module_load
from mlmodels.util import load_config

model_uri    = "model_tf.1_lstm.py"
module        =  module_load( model_uri= model_uri )                           # Load file definition

model_pars, data_pars, compute_pars, out_pars = module.get_params(param_pars={
    'choice':'json',
    'config_mode':'test',
    'data_path':'../mlmodels/example/1_lstm.json'
})

#### Load parameters and train
model         =  module.Model(model_pars=model_pars, data_pars=data_pars, compute_pars=compute_pars)             # Create Model instance
model, sess   =  module.fit(model, data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)          # fit the model

#### Check inference
ypred       = module.predict(model, sess=sess,  data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)     # predict pipeline


```

---

### Using Scikit-learn's SVM for Titanic Problem from json file ([Example notebook](mlmodels/example/sklearn_titanic_svm.ipynb), [JSON file](mlmodels/example/sklearn_titanic_svm.json))

#### Import library and functions
```python
# import library
import mlmodels

#### Load model and data definitions from json
from mlmodels.models import module_load
from mlmodels.util import load_config

model_uri    = "model_sklearn.sklearn.py"
module        =  module_load( model_uri= model_uri )                           # Load file definition

model_pars, data_pars, compute_pars, out_pars = module.get_params(param_pars={
    'choice':'json',
    'config_mode':'test',
    'data_path':'../mlmodels/example/sklearn_titanic_svm.json'
})

#### Load Parameters and Train

model         =  module.Model(model_pars=model_pars, data_pars=data_pars, compute_pars=compute_pars)             # Create Model instance
model, sess   =  module.fit(model, data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)          # fit the model


#### Inference
ypred       = module.predict(model,  data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)     # predict pipeline
ypred


#### Check metrics
import pandas as pd
from sklearn.metrics import roc_auc_score

y = pd.read_csv('../mlmodels/dataset/tabular/titanic_train_preprocessed.csv')['Survived'].values
roc_auc_score(y, ypred)


```

---

### Using Scikit-learn's Random Forest for Titanic Problem from json file ([Example notebook](mlmodels/example/sklearn_titanic_randomForest.ipynb), [JSON file](mlmodels/example/sklearn_titanic_randomForest.json))

#### Import library and functions
```python
# import library
import mlmodels

#### Load model and data definitions from json
from mlmodels.models import module_load
from mlmodels.util import load_config

model_uri    = "model_sklearn.sklearn.py"
module        =  module_load( model_uri= model_uri )                           # Load file definition

model_pars, data_pars, compute_pars, out_pars = module.get_params(param_pars={
    'choice':'json',
    'config_mode':'test',
    'data_path':'../mlmodels/example/sklearn_titanic_randomForest.json'
})


#### Load Parameters and Train
model         =  module.Model(model_pars=model_pars, data_pars=data_pars, compute_pars=compute_pars)             # Create Model instance
model, sess   =  module.fit(model, data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)          # fit the model


#### Inference

ypred       = module.predict(model,  data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)     # predict pipeline
ypred

#### Check metrics
import pandas as pd
from sklearn.metrics import roc_auc_score

y = pd.read_csv('../mlmodels/dataset/tabular/titanic_train_preprocessed.csv')['Survived'].values
roc_auc_score(y, ypred)

```

---

### Using Autogluon for Titanic Problem from json file ([Example notebook](mlmodels/example/gluon_automl_titanic.ipynb), [JSON file](mlmodels/example/gluon_automl.json))

#### Import library and functions
```python
# import library
import mlmodels

#### Load model and data definitions from json
from mlmodels.models import module_load
from mlmodels.util import load_config

model_uri    = "model_gluon.gluon_automl.py"
module        =  module_load( model_uri= model_uri )                           # Load file definition

model_pars, data_pars, compute_pars, out_pars = module.get_params(
    choice='json',
    config_mode= 'test',
    data_path= '../mlmodels/example/gluon_automl.json'
)


#### Load Parameters and Train
model         =  module.Model(model_pars=model_pars, compute_pars=compute_pars)             # Create Model instance
model   =  module.fit(model, model_pars=model_pars, data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)          # fit the model
model.model.fit_summary()


#### Check inference
ypred       = module.predict(model,  data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)     # predict pipeline

#### Check metrics
model.model.model_performance

import pandas as pd
from sklearn.metrics import roc_auc_score

y = pd.read_csv('../mlmodels/dataset/tabular/titanic_train_preprocessed.csv')['Survived'].values
roc_auc_score(y, ypred)


```

---
---

### Using hyper-params (optuna) for Titanic Problem from json file ([Example notebook](mlmodels/example/sklearn_titanic_randomForest_example2.ipynb), [JSON file](mlmodels/example/hyper_titanic_randomForest.json))

#### Import library and functions
```python
# import library
from mlmodels.models import module_load
from mlmodels.optim import optim
from mlmodels.util import params_json_load


#### Load model and data definitions from json

###  hypermodel_pars, model_pars, ....
model_uri   = "model_sklearn.sklearn.py"
config_path = path_norm( 'example/hyper_titanic_randomForest.json'  )
config_mode = "test"  ### test/prod



#### Model Parameters
hypermodel_pars, model_pars, data_pars, compute_pars, out_pars = params_json_load(config_path, config_mode= config_mode)
print( hypermodel_pars, model_pars, data_pars, compute_pars, out_pars)


module            =  module_load( model_uri= model_uri )                      
model_pars_update = optim(
    model_uri       = model_uri,
    hypermodel_pars = hypermodel_pars,
    model_pars      = model_pars,
    data_pars       = data_pars,
    compute_pars    = compute_pars,
    out_pars        = out_pars
)


#### Load Parameters and Train
model         =  module.Model(model_pars=model_pars_update, data_pars=data_pars, compute_pars=compute_pars)y
model, sess   =  module.fit(model, data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)

#### Check inference
ypred         = module.predict(model,  data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)     # predict pipeline
ypred


#### Check metrics
import pandas as pd
from sklearn.metrics import roc_auc_score

y = pd.read_csv( path_norm('dataset/tabular/titanic_train_preprocessed.csv') )
y = y['Survived'].values
roc_auc_score(y, ypred)


```


---

### Using LightGBM for Titanic Problem from json file ([Example notebook](mlmodels/example/model_lightgbm.ipynb), [JSON file](mlmodels/example/lightgbm_titanic.json))

#### Import library and functions
```python
# import library
import mlmodels
from mlmodels.models import module_load
from mlmodels.util import path_norm_dict, path_norm
import json

#### Load model and data definitions from json
# Model defination
model_uri    = "model_sklearn.model_lightgbm.py"
module        =  module_load( model_uri= model_uri)

# Path to JSON
data_path = '../dataset/json/lightgbm_titanic.json'  

# Model Parameters
pars = json.load(open( data_path , mode='r'))
for key, pdict in  pars.items() :
  globals()[key] = path_norm_dict( pdict   )   ###Normalize path

#### Load Parameters and Train
model = module.Model(model_pars, data_pars, compute_pars) # create model instance
model, session = module.fit(model, data_pars, compute_pars, out_pars) # fit model


#### Check inference
ypred       = module.predict(model,  data_pars=data_pars, compute_pars=compute_pars, out_pars=out_pars)     # get predictions
ypred


#### Check metrics
metrics_val = module.fit_metrics(model, data_pars, compute_pars, out_pars)
metrics_val 

```

---




### Using Vision CNN RESNET18 for MNIST dataset  ([Example notebook](mlmodels/example/model_restnet18.ipynb), [JSON file](mlmodels/model_tch/torchhub_cnn.json))

```python
# import library
import mlmodels
from mlmodels.models import module_load
from mlmodels.util import path_norm_dict, path_norm, params_json_load
import json


#### Model URI and Config JSON
model_uri   = "model_tch.torchhub.py"
config_path = path_norm( 'model_tch/torchhub_cnn.json'  )
config_mode = "test"  ### test/prod





#### Model Parameters
hypermodel_pars, model_pars, data_pars, compute_pars, out_pars = params_json_load(config_path, config_mode= config_mode)
print( hypermodel_pars, model_pars, data_pars, compute_pars, out_pars)


#### Setup Model 
module         = module_load( model_uri)
model          = module.Model(model_pars, data_pars, compute_pars) 
`
#### Fit
model, session = module.fit(model, data_pars, compute_pars, out_pars)           #### fit model
metrics_val    = module.fit_metrics(model, data_pars, compute_pars, out_pars)   #### Check fit metrics
print(metrics_val)


#### Inference
ypred          = module.predict(model, session, data_pars, compute_pars, out_pars)   
print(ypred)




```
---



### Using ARMDN Time Series : Ass for MNIST dataset  ([Example notebook](mlmodels/example/model_timeseries_armdn.ipynb), [JSON file](mlmodels/model_keras/armdn.json))



```python
# import library
import mlmodels
from mlmodels.models import module_load
from mlmodels.util import path_norm_dict, path_norm, params_json_load
import json


#### Model URI and Config JSON
model_uri   = "model_keras.ardmn.py"
config_path = path_norm( 'model_keras/ardmn.json'  )
config_mode = "test"  ### test/prod




#### Model Parameters
hypermodel_pars, model_pars, data_pars, compute_pars, out_pars = params_json_load(config_path, config_mode= config_mode)
print( hypermodel_pars, model_pars, data_pars, compute_pars, out_pars)


#### Setup Model 
module         = module_load( model_uri)
model          = module.Model(model_pars, data_pars, compute_pars) 
`
#### Fit
model, session = module.fit(model, data_pars, compute_pars, out_pars)           #### fit model
metrics_val    = module.fit_metrics(model, data_pars, compute_pars, out_pars)   #### Check fit metrics
print(metrics_val)


#### Inference
ypred          = module.predict(model, session, data_pars, compute_pars, out_pars)   
print(ypred)



#### Save/Load
module.save(model, save_pars ={ 'path': out_pars['path'] +"/model/"})

model2 = module.load(load_pars ={ 'path': out_pars['path'] +"/model/"})



```
---



